{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lochieh19798/Data-analysis/blob/main/Figure2mod.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edition control"
      ],
      "metadata": {
        "id": "Soz1YsEaL0XZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"lochieh19798\"\n",
        "!git config --global user.email \"lochieh19798@gmail.com\""
      ],
      "metadata": {
        "id": "2M1BW0t8Lz5d"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lochieh19798/data-analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrOB_TJxMC9j",
        "outputId": "389fe4d0-f38b-4dec-9c1b-3001a06f5681"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data-analysis'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "Receiving objects: 100% (74/74), 4.98 MiB | 10.21 MiB/s, done.\n",
            "remote: Total 74 (delta 36), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gCXII-AEgAjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad24138b-1429-40a4-a6c9-c4ca9d55e2ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m122.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.9/253.9 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# â•”â•â•¡ Cell 0 â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# If youâ€™re on Colab, install any non-preinstalled libraries:\n",
        "!pip install -q catboost shap scikit-learn==1.4.2 matplotlib pandas numpy\n",
        "!pip install -q --upgrade xgboost\n",
        "!pip install -q shap --no-deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUmxufPcmQEf",
        "outputId": "56967a84-3bee-4fc4-d926-e50fde88c127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patched XGBModel.feature_weights â†’ None\n"
          ]
        }
      ],
      "source": [
        "from xgboost.sklearn import XGBModel\n",
        "XGBModel.feature_weights = None\n",
        "print(\"Patched XGBModel.feature_weights â†’\", XGBModel.feature_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lplcCkEkje8m"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 1 â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# Imports & global configuration\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "from IPython.display import display\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import (\n",
        "    OneHotEncoder,\n",
        "    StandardScaler,\n",
        "    OrdinalEncoder\n",
        ")\n",
        "from sklearn.impute import (\n",
        "    KNNImputer,\n",
        "    SimpleImputer\n",
        "    # â† no IterativeImputer here\n",
        ")\n",
        "from sklearn.metrics import roc_auc_score, RocCurveDisplay\n",
        "\n",
        "# Classifiers\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    ExtraTreesClassifier,\n",
        "    AdaBoostClassifier,\n",
        "    HistGradientBoostingClassifier\n",
        ")\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "plt.style.use(\"default\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AWh_G5BjgON",
        "outputId": "b36e3126-b7b9-4a13-8fa2-0a43d96d4ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Missing Value Percentage per Feature:\n",
            "                                                                                          variable  missing_pct\n",
            "                                                                                      Baseline LAD        32.7%\n",
            "                                                                                   Change in EQ 5D        27.0%\n",
            "                                                            Anxiety/Depression question (Baseline)        25.6%\n",
            "                                                               Pain/Discomfort question (Baseline)        25.6%\n",
            "                                                              Usual activities question (Baseline)        25.6%\n",
            "                                                                     Self-care question (Baseline)        25.6%\n",
            "                                     Visual analogue score: Your own health state today (Baseline)        25.6%\n",
            "                                                                      Mobility question (Baseline)        25.6%\n",
            "                                                                          Coldest Temperature LIPV        25.3%\n",
            "                                                                                     Baseline LVEF        23.8%\n",
            "                                                                          Coldest temperature RSPV        23.8%\n",
            "                                                                          Coldest Temperature LSPV        23.8%\n",
            "                                                                          Coldest Temperature RIPV        23.8%\n",
            "                                                                                 AF_time_procedure         9.6%\n",
            "Left atrial dwell time: time from first cryocatheter insertion to last cryocatheter removal (mins)         7.8%\n",
            "                                                                          Total fluoro time (mins)         7.5%\n",
            "                                                                              Energy duration LIPV         4.3%\n",
            "                                                    Were all targeted PVs isolated (Investigator)?         4.3%\n",
            "                                       Subject taking Class I or III AAD at baseline (1=Yes, 0=No)         2.8%\n",
            "                                                                              Energy duration LSPV         2.5%\n",
            "                                                                              Energy duration RSPV         2.1%\n",
            "                                                                              Energy duration RIPV         2.1%\n",
            "                                                                                  LIPV PV isolated         1.1%\n",
            "                                                                                 Pre Procedural CT         0.7%\n",
            "                                                                                     RIPV isolated         0.7%\n",
            "                                                                                     LSPV isolated         0.7%\n",
            "                                                                                     RSPV Isolated         0.7%\n",
            "                                                                                 Ensite 3D mapping         0.4%\n",
            "                                                                                               BMI         0.4%\n",
            "                                                                                               age         0.0%\n",
            "                                                                                       CHAD2 score         0.0%\n",
            "                            Total procedure time: Venous access to last cryoatheter removal (mins)         0.0%\n",
            "                                                           Total no of ablation application number         0.0%\n",
            "                                                                                 CHA2DS2VASc score         0.0%\n",
            "                                                                                               CAD         0.0%\n",
            "                                                                                    Sex (F=1, M=0)         0.0%\n",
            "                                                                                                HF         0.0%\n",
            "                                                                                          Diabetes         0.0%\n",
            "                                                                                      Hypertension         0.0%\n",
            "                                                                                    History of TIA         0.0%\n",
            "                                                                                            stroke         0.0%\n",
            "                                                                                          AF_Parox         0.0%\n",
            "                                                                                        AF_Persist         0.0%\n",
            "                                                                        Non-PVI ablation performed         0.0%\n",
            "                                                                                      CTI ablation         0.0%\n",
            "                                   Mapping/navigational tools: Intracardiac echocardiography (ICE)         0.0%\n",
            "                               Was subject taking Class I or Class III AAD at procedure discharge?         0.0%\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•¡ Cell 2 â€“ load data & build feature lists with missingâ€% report â•â•â•â•â•â•\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Dataâ€loading helper (as before)\n",
        "DATA_PATH = \"/content/data-analysis/CRYOANALYSIS.csv\"\n",
        "def load_and_prepare_data(csv_path: str = DATA_PATH) -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    # (1) Recurrence flags\n",
        "    df[\"Survival_time\"] = pd.to_numeric(df[\"Survival_time\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"Survival_time\", \"Recurrence\"])\n",
        "    df[\"Recurrence_1yr\"] = ((df[\"Survival_time\"] <= 365) & (df[\"Recurrence\"] == 1)).astype(int)\n",
        "    df[\"Recurrence_2yr\"] = ((df[\"Survival_time\"] <= 730) & (df[\"Recurrence\"] == 1)).astype(int)\n",
        "    # (2) AF type oneâ€hot\n",
        "    af_col = \"Baseline AF Type(1=paroxysmal, 2=persistent)\"\n",
        "    df[\"AF_Parox\"]   = (df[af_col] == 1).astype(int)\n",
        "    df[\"AF_Persist\"] = (df[af_col] == 2).astype(int)\n",
        "    return df\n",
        "\n",
        "# 2. Load the dataset\n",
        "DATA_PATH = Path(\"/content/data-analysis/CRYOANALYSIS.csv\")\n",
        "assert DATA_PATH.exists(), f\"{DATA_PATH} not found â€“ upload it first!\"\n",
        "df = load_and_prepare_data(DATA_PATH)\n",
        "\n",
        "# 3. Feature lists\n",
        "cont = [\n",
        "    \"age\", \"BMI\",\n",
        "    \"Baseline LVEF\", \"Baseline LAD\", \"CHA2DS2VASc score\", \"CHAD2 score\", \"AF_time_procedure\",\n",
        "    \"Total no of ablation application number\", \"Mobility question (Baseline)\",\n",
        "    \"Self-care question (Baseline)\", \"Usual activities question (Baseline)\",\n",
        "    \"Pain/Discomfort question (Baseline)\", \"Anxiety/Depression question (Baseline)\",\n",
        "    \"Visual analogue score: Your own health state today (Baseline)\",\n",
        "    \"Total procedure time: Venous access to last cryoatheter removal (mins)\",\n",
        "    \"Total fluoro time (mins)\", \"Energy duration LSPV\", \"Coldest Temperature LSPV\",\n",
        "    \"Energy duration LIPV\", \"Coldest Temperature LIPV\",\n",
        "    \"Energy duration RSPV\", \"Coldest temperature RSPV\",\n",
        "    \"Energy duration RIPV\", \"Coldest Temperature RIPV\",\n",
        "    \"Left atrial dwell time: time from first cryocatheter insertion to last cryocatheter removal (mins)\",\n",
        "    \"Change in EQ 5D\"\n",
        "    # \"Time to isolation LSPV\", \"Time to isolation LIPV\", \"Time to isolation RSPV\",\"Time to isolation RIPV\",\n",
        "]\n",
        "\n",
        "cat = [\n",
        "    \"Sex (F=1, M=0)\", \"Hypertension\", \"Diabetes\", \"HF\", \"CAD\", \"stroke\",\n",
        "    \"History of TIA\", \"Subject taking Class I or III AAD at baseline (1=Yes, 0=No)\",\n",
        "    \"LSPV isolated\", \"LIPV PV isolated\", \"RSPV Isolated\", \"RIPV isolated\",\n",
        "    \"Were all targeted PVs isolated (Investigator)?\",\n",
        "    \"AF_Parox\", \"AF_Persist\",\n",
        "    \"CTI ablation\",\n",
        "    \"Non-PVI ablation performed\",\n",
        "    \"Was subject taking Class I or Class III AAD at procedure discharge?\",\n",
        "    \"Mapping/navigational tools: Intracardiac echocardiography (ICE)\",\n",
        "    \"Pre Procedural CT\",\n",
        "    \"Ensite 3D mapping\"\n",
        "]\n",
        "\n",
        "TARGET = \"Recurrence_2yr\"\n",
        "\n",
        "# 4. Report missingâ€value percentages for every feature\n",
        "all_feats = cont + cat\n",
        "missing_pct = df[all_feats].isna().mean() * 100\n",
        "missing_report = (\n",
        "    missing_pct\n",
        "      .sort_values(ascending=False)\n",
        "      .rename(\"missing_pct\")\n",
        "      .reset_index()\n",
        "      .rename(columns={\"index\": \"variable\"})\n",
        ")\n",
        "print(\"ðŸ“Š Missing Value Percentage per Feature:\")\n",
        "print(missing_report.to_string(index=False, float_format=\"%.1f%%\"))\n",
        "\n",
        "# 5. Gentle column check: warn & drop if still missing\n",
        "missing_cont = [c for c in cont if c not in df.columns]\n",
        "missing_cat  = [c for c in cat  if c not in df.columns]\n",
        "if missing_cont or missing_cat:\n",
        "    print(\"\\nâš ï¸  WARNING â€“ some expected columns are missing and will be skipped.\")\n",
        "    print(\"   Missing continuous :\", missing_cont)\n",
        "    print(\"   Missing categorical:\", missing_cat)\n",
        "\n",
        "cont = [c for c in cont if c in df.columns]\n",
        "cat  = [c for c in cat  if c in df.columns]\n",
        "\n",
        "# From here on, the rest of the notebook runs as before...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVMwLeDVji9q",
        "outputId": "3360643c-2a61-4bef-ebe9-63474e26f147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split sizes:\n",
            "  â€¢ Train:      179\n",
            "  â€¢ Test:       45\n",
            "  â€¢ Validation: 57\n",
            "\n",
            "Event rates:\n",
            "  â€¢ Overall:    19.22%\n",
            "  â€¢ Train:      18.99%\n",
            "  â€¢ Test:       20.00%\n",
            "  â€¢ Validation: 19.30%\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•¡ Cell 3 â€“ stratified 3-way split: train/test/validation â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1) Sort by date if you still want a temporal ordering internally (optional)\n",
        "df[\"ProcedureDate\"] = pd.to_datetime(df[\"ProcedureDate\"])\n",
        "df_sorted = df.sort_values(\"ProcedureDate\")\n",
        "\n",
        "# 2) Extract features & target\n",
        "X_all = df_sorted[cont + cat]\n",
        "y_all = df_sorted[TARGET].astype(int)\n",
        "\n",
        "# 3) Initial 20% hold-out for future validation (stratified by target)\n",
        "X_temp, X_val, y_temp, y_val = train_test_split(\n",
        "    X_all, y_all,\n",
        "    test_size=0.20,\n",
        "    stratify=y_all,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# 4) Of the remaining 80%, take a 20% slice for an internal test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_temp, y_temp,\n",
        "    test_size=0.20,\n",
        "    stratify=y_temp,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# 5) Report sizes and event rates\n",
        "print(\"Split sizes:\")\n",
        "print(f\"  â€¢ Train:      {len(y_train)}\")\n",
        "print(f\"  â€¢ Test:       {len(y_test)}\")\n",
        "print(f\"  â€¢ Validation: {len(y_val)}\\n\")\n",
        "\n",
        "print(\"Event rates:\")\n",
        "print(f\"  â€¢ Overall:    {y_all.mean():.2%}\")\n",
        "print(f\"  â€¢ Train:      {y_train.mean():.2%}\")\n",
        "print(f\"  â€¢ Test:       {y_test.mean():.2%}\")\n",
        "print(f\"  â€¢ Validation: {y_val.mean():.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•¡ Cell 4 â€“ Pre-processing pipelines â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# (Make sure to enable the experimental IterativeImputer)\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.pipeline           import Pipeline\n",
        "from sklearn.impute             import IterativeImputer, SimpleImputer\n",
        "from sklearn.preprocessing      import StandardScaler, PowerTransformer, OneHotEncoder\n",
        "from sklearn.compose            import ColumnTransformer\n",
        "\n",
        "# Numeric pipeline: iterative imputation â†’ power transform â†’ scaling\n",
        "numeric_pipe = Pipeline([\n",
        "    (\"impute\", IterativeImputer(random_state=RANDOM_STATE)),\n",
        "    (\"power\",  PowerTransformer(method=\"yeo-johnson\")),\n",
        "    (\"scale\",  StandardScaler())\n",
        "])\n",
        "\n",
        "# Categorical pipeline: fill missing with \"Missing\" â†’ one-hot encode\n",
        "categorical_pipe = Pipeline([\n",
        "    (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "])\n",
        "\n",
        "# Full preprocessor: apply to continuous and categorical lists\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", numeric_pipe,       cont),\n",
        "    (\"cat\", categorical_pipe,   cat)\n",
        "], remainder=\"drop\")\n"
      ],
      "metadata": {
        "id": "blz14tHZe6mJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DKukFYJdbqbW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56da9ae1-6b6e-4f76-d848-95d70892aff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”´ Missing before imputation (numeric features):\n",
            "age                                                                                                    0\n",
            "BMI                                                                                                    1\n",
            "Baseline LVEF                                                                                         44\n",
            "Baseline LAD                                                                                          57\n",
            "CHA2DS2VASc score                                                                                      0\n",
            "CHAD2 score                                                                                            0\n",
            "AF_time_procedure                                                                                     18\n",
            "Total no of ablation application number                                                                0\n",
            "Mobility question (Baseline)                                                                          41\n",
            "Self-care question (Baseline)                                                                         41\n",
            "Usual activities question (Baseline)                                                                  41\n",
            "Pain/Discomfort question (Baseline)                                                                   41\n",
            "Anxiety/Depression question (Baseline)                                                                41\n",
            "Visual analogue score: Your own health state today (Baseline)                                         41\n",
            "Total procedure time: Venous access to last cryoatheter removal (mins)                                 0\n",
            "Total fluoro time (mins)                                                                              10\n",
            "Energy duration LSPV                                                                                   2\n",
            "Coldest Temperature LSPV                                                                              37\n",
            "Energy duration LIPV                                                                                   5\n",
            "Coldest Temperature LIPV                                                                              40\n",
            "Energy duration RSPV                                                                                   2\n",
            "Coldest temperature RSPV                                                                              38\n",
            "Energy duration RIPV                                                                                   2\n",
            "Coldest Temperature RIPV                                                                              38\n",
            "Left atrial dwell time: time from first cryocatheter insertion to last cryocatheter removal (mins)    11\n",
            "Change in EQ 5D                                                                                       45\n",
            "dtype: int64\n",
            "\n",
            "ðŸŸ¢ Missing after IterativeImputer + PowerTransformer:\n",
            "age                                                                                                   0\n",
            "BMI                                                                                                   0\n",
            "Baseline LVEF                                                                                         0\n",
            "Baseline LAD                                                                                          0\n",
            "CHA2DS2VASc score                                                                                     0\n",
            "CHAD2 score                                                                                           0\n",
            "AF_time_procedure                                                                                     0\n",
            "Total no of ablation application number                                                               0\n",
            "Mobility question (Baseline)                                                                          0\n",
            "Self-care question (Baseline)                                                                         0\n",
            "Usual activities question (Baseline)                                                                  0\n",
            "Pain/Discomfort question (Baseline)                                                                   0\n",
            "Anxiety/Depression question (Baseline)                                                                0\n",
            "Visual analogue score: Your own health state today (Baseline)                                         0\n",
            "Total procedure time: Venous access to last cryoatheter removal (mins)                                0\n",
            "Total fluoro time (mins)                                                                              0\n",
            "Energy duration LSPV                                                                                  0\n",
            "Coldest Temperature LSPV                                                                              0\n",
            "Energy duration LIPV                                                                                  0\n",
            "Coldest Temperature LIPV                                                                              0\n",
            "Energy duration RSPV                                                                                  0\n",
            "Coldest temperature RSPV                                                                              0\n",
            "Energy duration RIPV                                                                                  0\n",
            "Coldest Temperature RIPV                                                                              0\n",
            "Left atrial dwell time: time from first cryocatheter insertion to last cryocatheter removal (mins)    0\n",
            "Change in EQ 5D                                                                                       0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          age       BMI  Baseline LVEF  Baseline LAD  CHA2DS2VASc score  \\\n",
              "128  0.306690 -2.695985       2.256020     -0.035082           0.816136   \n",
              "154 -0.764668 -1.718153      -1.638789     -0.353458           0.816136   \n",
              "276  0.407181 -3.076736      -0.143123     -0.014944          -1.765314   \n",
              "164 -1.277493  0.192692      -0.868812      0.091638          -1.765314   \n",
              "56  -0.434878 -1.450036       0.353945     -1.285939          -0.565279   \n",
              "\n",
              "     CHAD2 score  AF_time_procedure  Total no of ablation application number  \\\n",
              "128     1.063746           0.380852                                -0.172024   \n",
              "154     1.063746          -0.311250                                 0.366003   \n",
              "276    -1.146417           0.284545                                -0.172024   \n",
              "164    -1.146417          -0.515793                                 0.366003   \n",
              "56     -1.146417           0.126799                                -0.172024   \n",
              "\n",
              "     Mobility question (Baseline)  Self-care question (Baseline)  ...  \\\n",
              "128                     -0.478756                      -0.179739  ...   \n",
              "154                     -0.478756                      -0.179739  ...   \n",
              "276                     -0.478756                      -0.179739  ...   \n",
              "164                     -0.478756                      -0.179739  ...   \n",
              "56                       0.494720                      -0.320770  ...   \n",
              "\n",
              "     Energy duration LSPV  Coldest Temperature LSPV  Energy duration LIPV  \\\n",
              "128             -0.169332                 -0.541701              0.017336   \n",
              "154             -0.169332                 -0.746231              0.017336   \n",
              "276             -0.169332                  1.668595              0.017336   \n",
              "164             -0.169332                  1.230503              1.482320   \n",
              "56              -0.169332                  0.085402              0.017336   \n",
              "\n",
              "     Coldest Temperature LIPV  Energy duration RSPV  Coldest temperature RSPV  \\\n",
              "128                 -0.584491             -0.081233                 -1.452025   \n",
              "154                  0.191863              0.230314                 -0.191331   \n",
              "276                  0.778259              0.230314                 -0.191331   \n",
              "164                 -0.197069              0.230314                  0.322677   \n",
              "56                  -0.311874              0.230314                 -0.662338   \n",
              "\n",
              "     Energy duration RIPV  Coldest Temperature RIPV  \\\n",
              "128             -0.004267                  0.034946   \n",
              "154              0.880168                  0.493780   \n",
              "276             -0.004267                 -1.140601   \n",
              "164             -0.004267                  0.649173   \n",
              "56              -0.004267                 -0.698509   \n",
              "\n",
              "     Left atrial dwell time: time from first cryocatheter insertion to last cryocatheter removal (mins)  \\\n",
              "128                                          -0.860967                                                    \n",
              "154                                          -0.225780                                                    \n",
              "276                                          -0.063261                                                    \n",
              "164                                           0.015393                                                    \n",
              "56                                           -1.285353                                                    \n",
              "\n",
              "     Change in EQ 5D  \n",
              "128         0.401817  \n",
              "154         1.065214  \n",
              "276         0.064858  \n",
              "164         0.064858  \n",
              "56          0.187132  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-910f47b3-8ca9-4515-9660-0feac7b73fc9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Baseline LVEF</th>\n",
              "      <th>Baseline LAD</th>\n",
              "      <th>CHA2DS2VASc score</th>\n",
              "      <th>CHAD2 score</th>\n",
              "      <th>AF_time_procedure</th>\n",
              "      <th>Total no of ablation application number</th>\n",
              "      <th>Mobility question (Baseline)</th>\n",
              "      <th>Self-care question (Baseline)</th>\n",
              "      <th>...</th>\n",
              "      <th>Energy duration LSPV</th>\n",
              "      <th>Coldest Temperature LSPV</th>\n",
              "      <th>Energy duration LIPV</th>\n",
              "      <th>Coldest Temperature LIPV</th>\n",
              "      <th>Energy duration RSPV</th>\n",
              "      <th>Coldest temperature RSPV</th>\n",
              "      <th>Energy duration RIPV</th>\n",
              "      <th>Coldest Temperature RIPV</th>\n",
              "      <th>Left atrial dwell time: time from first cryocatheter insertion to last cryocatheter removal (mins)</th>\n",
              "      <th>Change in EQ 5D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>0.306690</td>\n",
              "      <td>-2.695985</td>\n",
              "      <td>2.256020</td>\n",
              "      <td>-0.035082</td>\n",
              "      <td>0.816136</td>\n",
              "      <td>1.063746</td>\n",
              "      <td>0.380852</td>\n",
              "      <td>-0.172024</td>\n",
              "      <td>-0.478756</td>\n",
              "      <td>-0.179739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.169332</td>\n",
              "      <td>-0.541701</td>\n",
              "      <td>0.017336</td>\n",
              "      <td>-0.584491</td>\n",
              "      <td>-0.081233</td>\n",
              "      <td>-1.452025</td>\n",
              "      <td>-0.004267</td>\n",
              "      <td>0.034946</td>\n",
              "      <td>-0.860967</td>\n",
              "      <td>0.401817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>-0.764668</td>\n",
              "      <td>-1.718153</td>\n",
              "      <td>-1.638789</td>\n",
              "      <td>-0.353458</td>\n",
              "      <td>0.816136</td>\n",
              "      <td>1.063746</td>\n",
              "      <td>-0.311250</td>\n",
              "      <td>0.366003</td>\n",
              "      <td>-0.478756</td>\n",
              "      <td>-0.179739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.169332</td>\n",
              "      <td>-0.746231</td>\n",
              "      <td>0.017336</td>\n",
              "      <td>0.191863</td>\n",
              "      <td>0.230314</td>\n",
              "      <td>-0.191331</td>\n",
              "      <td>0.880168</td>\n",
              "      <td>0.493780</td>\n",
              "      <td>-0.225780</td>\n",
              "      <td>1.065214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>0.407181</td>\n",
              "      <td>-3.076736</td>\n",
              "      <td>-0.143123</td>\n",
              "      <td>-0.014944</td>\n",
              "      <td>-1.765314</td>\n",
              "      <td>-1.146417</td>\n",
              "      <td>0.284545</td>\n",
              "      <td>-0.172024</td>\n",
              "      <td>-0.478756</td>\n",
              "      <td>-0.179739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.169332</td>\n",
              "      <td>1.668595</td>\n",
              "      <td>0.017336</td>\n",
              "      <td>0.778259</td>\n",
              "      <td>0.230314</td>\n",
              "      <td>-0.191331</td>\n",
              "      <td>-0.004267</td>\n",
              "      <td>-1.140601</td>\n",
              "      <td>-0.063261</td>\n",
              "      <td>0.064858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>-1.277493</td>\n",
              "      <td>0.192692</td>\n",
              "      <td>-0.868812</td>\n",
              "      <td>0.091638</td>\n",
              "      <td>-1.765314</td>\n",
              "      <td>-1.146417</td>\n",
              "      <td>-0.515793</td>\n",
              "      <td>0.366003</td>\n",
              "      <td>-0.478756</td>\n",
              "      <td>-0.179739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.169332</td>\n",
              "      <td>1.230503</td>\n",
              "      <td>1.482320</td>\n",
              "      <td>-0.197069</td>\n",
              "      <td>0.230314</td>\n",
              "      <td>0.322677</td>\n",
              "      <td>-0.004267</td>\n",
              "      <td>0.649173</td>\n",
              "      <td>0.015393</td>\n",
              "      <td>0.064858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>-0.434878</td>\n",
              "      <td>-1.450036</td>\n",
              "      <td>0.353945</td>\n",
              "      <td>-1.285939</td>\n",
              "      <td>-0.565279</td>\n",
              "      <td>-1.146417</td>\n",
              "      <td>0.126799</td>\n",
              "      <td>-0.172024</td>\n",
              "      <td>0.494720</td>\n",
              "      <td>-0.320770</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.169332</td>\n",
              "      <td>0.085402</td>\n",
              "      <td>0.017336</td>\n",
              "      <td>-0.311874</td>\n",
              "      <td>0.230314</td>\n",
              "      <td>-0.662338</td>\n",
              "      <td>-0.004267</td>\n",
              "      <td>-0.698509</td>\n",
              "      <td>-1.285353</td>\n",
              "      <td>0.187132</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-910f47b3-8ca9-4515-9660-0feac7b73fc9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-910f47b3-8ca9-4515-9660-0feac7b73fc9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-910f47b3-8ca9-4515-9660-0feac7b73fc9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fe836ab3-c2cd-4be9-a372-330a7aafd1bd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe836ab3-c2cd-4be9-a372-330a7aafd1bd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fe836ab3-c2cd-4be9-a372-330a7aafd1bd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# â•”â•â•¡ Cell 4b â€“ preview IterativeImputer + PowerTransformer on numeric features â•â•â•â•â•â•â•â•—\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "\n",
        "# (Optionally suppress FutureWarnings or ConvergenceWarnings)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "# 1. Show missing counts before\n",
        "num_train = X_train[cont].copy()\n",
        "print(\"ðŸ”´ Missing before imputation (numeric features):\")\n",
        "print(num_train.isna().sum())\n",
        "\n",
        "# 2. Fit & transform with your updated numeric_pipe\n",
        "num_imputed = pd.DataFrame(\n",
        "    numeric_pipe.fit_transform(num_train),\n",
        "    columns=cont,\n",
        "    index=num_train.index\n",
        ")\n",
        "\n",
        "# 3. Show missing counts after\n",
        "print(\"\\nðŸŸ¢ Missing after IterativeImputer + PowerTransformer:\")\n",
        "print(num_imputed.isna().sum())\n",
        "\n",
        "# 4. Display first few rows of the transformed DataFrame\n",
        "display(num_imputed.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7QMFLyRLcF99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "cf597859-b314-4291-ae29-d7c9e8c32af4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”´ Missing before imputation (categorical features):\n",
            "Sex (F=1, M=0)                                                          0\n",
            "Hypertension                                                            0\n",
            "Diabetes                                                                0\n",
            "HF                                                                      0\n",
            "CAD                                                                     0\n",
            "stroke                                                                  0\n",
            "History of TIA                                                          0\n",
            "Subject taking Class I or III AAD at baseline (1=Yes, 0=No)             5\n",
            "LSPV isolated                                                           1\n",
            "LIPV PV isolated                                                        2\n",
            "RSPV Isolated                                                           2\n",
            "RIPV isolated                                                           2\n",
            "Were all targeted PVs isolated (Investigator)?                         10\n",
            "AF_Parox                                                                0\n",
            "AF_Persist                                                              0\n",
            "CTI ablation                                                            0\n",
            "Non-PVI ablation performed                                              0\n",
            "Was subject taking Class I or Class III AAD at procedure discharge?     0\n",
            "Mapping/navigational tools: Intracardiac echocardiography (ICE)         0\n",
            "Pre Procedural CT                                                       1\n",
            "Ensite 3D mapping                                                       0\n",
            "dtype: int64\n",
            "\n",
            "ðŸŸ¢ Missing after to_str â†’ SimpleImputer â†’ OneHotEncoder:\n",
            "0 total NaNs remaining\n",
            "\n",
            "ðŸ–¨ï¸ Sample of the imputed one-hot matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Sex (F=1, M=0)_0  Sex (F=1, M=0)_1  Hypertension_0  Hypertension_1  \\\n",
              "128               1.0               0.0             0.0             1.0   \n",
              "154               0.0               1.0             0.0             1.0   \n",
              "276               0.0               1.0             1.0             0.0   \n",
              "164               0.0               1.0             1.0             0.0   \n",
              "56                1.0               0.0             1.0             0.0   \n",
              "\n",
              "     Diabetes_0  Diabetes_1  HF_0  HF_1  CAD_0  CAD_1  \n",
              "128         0.0         1.0   1.0   0.0    1.0    0.0  \n",
              "154         0.0         1.0   1.0   0.0    0.0    1.0  \n",
              "276         1.0         0.0   1.0   0.0    1.0    0.0  \n",
              "164         1.0         0.0   1.0   0.0    1.0    0.0  \n",
              "56          1.0         0.0   1.0   0.0    1.0    0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d8e3e50-92b0-4d3d-8b36-c19e351536f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sex (F=1, M=0)_0</th>\n",
              "      <th>Sex (F=1, M=0)_1</th>\n",
              "      <th>Hypertension_0</th>\n",
              "      <th>Hypertension_1</th>\n",
              "      <th>Diabetes_0</th>\n",
              "      <th>Diabetes_1</th>\n",
              "      <th>HF_0</th>\n",
              "      <th>HF_1</th>\n",
              "      <th>CAD_0</th>\n",
              "      <th>CAD_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d8e3e50-92b0-4d3d-8b36-c19e351536f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0d8e3e50-92b0-4d3d-8b36-c19e351536f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0d8e3e50-92b0-4d3d-8b36-c19e351536f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d8f95ce9-d97b-451e-9e80-1e4b72588edc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d8f95ce9-d97b-451e-9e80-1e4b72588edc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d8f95ce9-d97b-451e-9e80-1e4b72588edc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(cat_imputed\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Sex (F=1, M=0)_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5477225575051662,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex (F=1, M=0)_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5477225575051662,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hypertension_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5477225575051662,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hypertension_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5477225575051662,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Diabetes_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5477225575051662,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Diabetes_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5477225575051662,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HF_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HF_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CAD_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.44721359549995804,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CAD_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.44721359549995804,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# â•”â•â•¡ Cell 4c â€“ preview string-cast â†’ impute â†’ one-hot on categorical features â•â•â•â•â•â•â•â•—\n",
        "from sklearn.pipeline          import Pipeline\n",
        "from sklearn.preprocessing     import FunctionTransformer, OneHotEncoder\n",
        "from sklearn.impute            import SimpleImputer\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Re-define categorical_pipe to cast â†’ impute â†’ one-hot\n",
        "categorical_pipe = Pipeline([\n",
        "    # cast every value to string\n",
        "    (\"to_str\",   FunctionTransformer(lambda X: X.astype(str), validate=False)),\n",
        "    # fill missing with literal \"Missing\"\n",
        "    (\"impute\",   SimpleImputer(strategy=\"constant\", fill_value=\"Missing\")),\n",
        "    # one-hot encode the strings\n",
        "    (\"onehot\",   OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "])\n",
        "\n",
        "# 2. Grab the raw cat columns (with NaNs)\n",
        "cat_train = X_train[cat].copy()\n",
        "print(\"ðŸ”´ Missing before imputation (categorical features):\")\n",
        "print(cat_train.isna().sum())\n",
        "\n",
        "# 3. Fit & transform via the updated pipeline\n",
        "cat_ohe_array = categorical_pipe.fit_transform(cat_train)\n",
        "\n",
        "# 4. Turn back into a DataFrame\n",
        "cat_ohe_cols = categorical_pipe.named_steps[\"onehot\"].get_feature_names_out(cat)\n",
        "cat_imputed  = pd.DataFrame(cat_ohe_array, columns=cat_ohe_cols, index=cat_train.index)\n",
        "\n",
        "print(\"\\nðŸŸ¢ Missing after to_str â†’ SimpleImputer â†’ OneHotEncoder:\")\n",
        "print(cat_imputed.isna().sum().sum(), \"total NaNs remaining\")\n",
        "\n",
        "print(\"\\nðŸ–¨ï¸ Sample of the imputed one-hot matrix:\")\n",
        "display(cat_imputed.iloc[:, :10].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bqXPfTpFZlGn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "1cb4a1c0-09ce-42bf-c7dc-7808815ed429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âž¡ï¸  Combined train matrix: 179 rows Ã— 75 cols\n",
            "ðŸ“¦  Total features = 75\n",
            "ðŸ”  Example feature names: ['age', 'BMI', 'Baseline LVEF', 'Baseline LAD', 'CHA2DS2VASc score', 'CHAD2 score', 'AF_time_procedure', 'Total no of ablation application number', 'Mobility question (Baseline)', 'Self-care question (Baseline)'] â€¦ ['Non-PVI ablation performed_1', 'Was subject taking Class I or Class III AAD at procedure discharge?_0', 'Was subject taking Class I or Class III AAD at procedure discharge?_1', 'Mapping/navigational tools: Intracardiac echocardiography (ICE)_0', 'Mapping/navigational tools: Intracardiac echocardiography (ICE)_1', 'Pre Procedural CT_0.0', 'Pre Procedural CT_1.0', 'Pre Procedural CT_nan', 'Ensite 3D mapping_0.0', 'Ensite 3D mapping_1.0']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          age       BMI  Baseline LVEF  Baseline LAD  CHA2DS2VASc score  \\\n",
              "128  0.306690 -2.695985       2.256020     -0.035082           0.816136   \n",
              "154 -0.764668 -1.718153      -1.638789     -0.353458           0.816136   \n",
              "276  0.407181 -3.076736      -0.143123     -0.014944          -1.765314   \n",
              "164 -1.277493  0.192692      -0.868812      0.091638          -1.765314   \n",
              "56  -0.434878 -1.450036       0.353945     -1.285939          -0.565279   \n",
              "\n",
              "     CHAD2 score  AF_time_procedure  Total no of ablation application number  \\\n",
              "128     1.063746           0.380852                                -0.172024   \n",
              "154     1.063746          -0.311250                                 0.366003   \n",
              "276    -1.146417           0.284545                                -0.172024   \n",
              "164    -1.146417          -0.515793                                 0.366003   \n",
              "56     -1.146417           0.126799                                -0.172024   \n",
              "\n",
              "     Mobility question (Baseline)  Self-care question (Baseline)  ...  \\\n",
              "128                     -0.478756                      -0.179739  ...   \n",
              "154                     -0.478756                      -0.179739  ...   \n",
              "276                     -0.478756                      -0.179739  ...   \n",
              "164                     -0.478756                      -0.179739  ...   \n",
              "56                       0.494720                      -0.320770  ...   \n",
              "\n",
              "     Non-PVI ablation performed_1  \\\n",
              "128                           0.0   \n",
              "154                           0.0   \n",
              "276                           0.0   \n",
              "164                           0.0   \n",
              "56                            0.0   \n",
              "\n",
              "     Was subject taking Class I or Class III AAD at procedure discharge?_0  \\\n",
              "128                                                0.0                       \n",
              "154                                                0.0                       \n",
              "276                                                0.0                       \n",
              "164                                                0.0                       \n",
              "56                                                 1.0                       \n",
              "\n",
              "     Was subject taking Class I or Class III AAD at procedure discharge?_1  \\\n",
              "128                                                1.0                       \n",
              "154                                                1.0                       \n",
              "276                                                1.0                       \n",
              "164                                                1.0                       \n",
              "56                                                 0.0                       \n",
              "\n",
              "     Mapping/navigational tools: Intracardiac echocardiography (ICE)_0  \\\n",
              "128                                                1.0                   \n",
              "154                                                1.0                   \n",
              "276                                                1.0                   \n",
              "164                                                1.0                   \n",
              "56                                                 1.0                   \n",
              "\n",
              "     Mapping/navigational tools: Intracardiac echocardiography (ICE)_1  \\\n",
              "128                                                0.0                   \n",
              "154                                                0.0                   \n",
              "276                                                0.0                   \n",
              "164                                                0.0                   \n",
              "56                                                 0.0                   \n",
              "\n",
              "     Pre Procedural CT_0.0  Pre Procedural CT_1.0  Pre Procedural CT_nan  \\\n",
              "128                    1.0                    0.0                    0.0   \n",
              "154                    1.0                    0.0                    0.0   \n",
              "276                    1.0                    0.0                    0.0   \n",
              "164                    1.0                    0.0                    0.0   \n",
              "56                     0.0                    1.0                    0.0   \n",
              "\n",
              "     Ensite 3D mapping_0.0  Ensite 3D mapping_1.0  \n",
              "128                    1.0                    0.0  \n",
              "154                    0.0                    1.0  \n",
              "276                    0.0                    1.0  \n",
              "164                    0.0                    1.0  \n",
              "56                     0.0                    1.0  \n",
              "\n",
              "[5 rows x 75 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f87d8b7-b5b3-4f9e-8cd2-ccc70d229c37\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Baseline LVEF</th>\n",
              "      <th>Baseline LAD</th>\n",
              "      <th>CHA2DS2VASc score</th>\n",
              "      <th>CHAD2 score</th>\n",
              "      <th>AF_time_procedure</th>\n",
              "      <th>Total no of ablation application number</th>\n",
              "      <th>Mobility question (Baseline)</th>\n",
              "      <th>Self-care question (Baseline)</th>\n",
              "      <th>...</th>\n",
              "      <th>Non-PVI ablation performed_1</th>\n",
              "      <th>Was subject taking Class I or Class III AAD at procedure discharge?_0</th>\n",
              "      <th>Was subject taking Class I or Class III AAD at procedure discharge?_1</th>\n",
              "      <th>Mapping/navigational tools: Intracardiac echocardiography (ICE)_0</th>\n",
              "      <th>Mapping/navigational tools: Intracardiac echocardiography (ICE)_1</th>\n",
              "      <th>Pre Procedural CT_0.0</th>\n",
              "      <th>Pre Procedural CT_1.0</th>\n",
              "      <th>Pre Procedural CT_nan</th>\n",
              "      <th>Ensite 3D mapping_0.0</th>\n",
              "      <th>Ensite 3D mapping_1.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>0.306690</td>\n",
              "      <td>-2.695985</td>\n",
              "      <td>2.256020</td>\n",
              "      <td>-0.035082</td>\n",
              "      <td>0.816136</td>\n",
              "      <td>1.063746</td>\n",
              "      <td>0.380852</td>\n",
              "      <td>-0.172024</td>\n",
              "      <td>-0.478756</td>\n",
              "      <td>-0.179739</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>-0.764668</td>\n",
              "      <td>-1.718153</td>\n",
              "      <td>-1.638789</td>\n",
              "      <td>-0.353458</td>\n",
              "      <td>0.816136</td>\n",
              "      <td>1.063746</td>\n",
              "      <td>-0.311250</td>\n",
              "      <td>0.366003</td>\n",
              "      <td>-0.478756</td>\n",
              "      <td>-0.179739</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>0.407181</td>\n",
              "      <td>-3.076736</td>\n",
              "      <td>-0.143123</td>\n",
              "      <td>-0.014944</td>\n",
              "      <td>-1.765314</td>\n",
              "      <td>-1.146417</td>\n",
              "      <td>0.284545</td>\n",
              "      <td>-0.172024</td>\n",
              "      <td>-0.478756</td>\n",
              "      <td>-0.179739</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>-1.277493</td>\n",
              "      <td>0.192692</td>\n",
              "      <td>-0.868812</td>\n",
              "      <td>0.091638</td>\n",
              "      <td>-1.765314</td>\n",
              "      <td>-1.146417</td>\n",
              "      <td>-0.515793</td>\n",
              "      <td>0.366003</td>\n",
              "      <td>-0.478756</td>\n",
              "      <td>-0.179739</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>-0.434878</td>\n",
              "      <td>-1.450036</td>\n",
              "      <td>0.353945</td>\n",
              "      <td>-1.285939</td>\n",
              "      <td>-0.565279</td>\n",
              "      <td>-1.146417</td>\n",
              "      <td>0.126799</td>\n",
              "      <td>-0.172024</td>\n",
              "      <td>0.494720</td>\n",
              "      <td>-0.320770</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 75 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f87d8b7-b5b3-4f9e-8cd2-ccc70d229c37')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f87d8b7-b5b3-4f9e-8cd2-ccc70d229c37 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f87d8b7-b5b3-4f9e-8cd2-ccc70d229c37');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1f152abf-22a9-4366-afa7-738b36b7477e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f152abf-22a9-4366-afa7-738b36b7477e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1f152abf-22a9-4366-afa7-738b36b7477e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_feats"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# â•”â•â•¡ Cell 4d â€“ inspect full preprocessed feature space â”€â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# 1) Reâ€build the ColumnTransformer as in Cell 4\n",
        "ct = ColumnTransformer([\n",
        "    (\"num\", numeric_pipe, cont),\n",
        "    (\"cat\", categorical_pipe, cat)\n",
        "], remainder=\"drop\")\n",
        "\n",
        "# 2) Fit & transform your training set\n",
        "X_tr_full = ct.fit_transform(X_train)\n",
        "\n",
        "# 3) Manually assemble the feature names:\n",
        "#    - numeric features keep their original names\n",
        "num_features = cont\n",
        "\n",
        "#    - categorical features come from the OneHotEncoder inside categorical_pipe\n",
        "cat_ohe_names = categorical_pipe.named_steps[\"onehot\"] \\\n",
        "                     .get_feature_names_out(cat)\n",
        "\n",
        "#    - combine\n",
        "feat_names = list(num_features) + list(cat_ohe_names)\n",
        "\n",
        "# 4) Report\n",
        "print(f\"âž¡ï¸  Combined train matrix: {X_tr_full.shape[0]} rows Ã— {X_tr_full.shape[1]} cols\")\n",
        "print(f\"ðŸ“¦  Total features = {len(feat_names)}\")\n",
        "print(\"ðŸ”  Example feature names:\", feat_names[:10], \"â€¦\", feat_names[-10:])\n",
        "\n",
        "# 5) (optional) display the first few rows in a DataFrame\n",
        "import pandas as pd\n",
        "df_feats = pd.DataFrame(X_tr_full, columns=feat_names, index=X_train.index)\n",
        "df_feats.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "woGe7ZS8pl6a"
      },
      "outputs": [],
      "source": [
        "# ------------- 4.3 Define candidate models ------------------------------\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_pipe, cont),\n",
        "        (\"cat\", categorical_pipe, cat)\n",
        "    ],\n",
        "    remainder=\"drop\"   # or \"passthrough\" if you have other cols\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KV0Ss9AWp-al"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 4.4 â€“ helper for CatBoost (just fill categoricals) â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "def prepare_for_catboost(\n",
        "    X: pd.DataFrame,\n",
        "    cat_cols: list[str]\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Copy X, replace any NaN in the specified categorical columns\n",
        "    with a literal 'Missing' string (so CatBoost sees it as a valid category).\n",
        "    Leave all other columns untouched (CatBoost will handle numeric NaNs if any).\n",
        "    \"\"\"\n",
        "    X_cb = X.copy()\n",
        "    for c in cat_cols:\n",
        "        X_cb[c] = X_cb[c].fillna(\"Missing\").astype(str)\n",
        "    return X_cb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "io8XnbfaomCe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfb1e769-3b91-4aca-9519-2d3c6c7ef600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
            "âœ… Best ExtraTrees params: {'clf__n_estimators': 100, 'clf__min_samples_split': 5, 'clf__min_samples_leaf': 2, 'clf__max_features': 'sqrt', 'clf__max_depth': None}\n",
            "âœ… Best CV AUC:          0.6603707139421425\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•¡ Cell 4.6 â€“ Faster tune of ExtraTrees via RandomizedSearchCV with SMOTE â•â•—\n",
        "from imblearn.pipeline      import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble       import ExtraTreesClassifier\n",
        "import numpy as np\n",
        "\n",
        "# 1) Pipeline: impute/encode â†’ SMOTE â†’ ExtraTrees\n",
        "et_pipe = ImbPipeline([\n",
        "    (\"prep\", preprocessor),\n",
        "    (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
        "    (\"clf\", ExtraTreesClassifier(\n",
        "        random_state=RANDOM_STATE,\n",
        "        class_weight=\"balanced\",\n",
        "        n_jobs=-1          # speed up individual fits\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 2) Narrower/random search space\n",
        "param_dist = {\n",
        "    \"clf__n_estimators\":     [100, 300, 500, 800],\n",
        "    \"clf__max_depth\":        [None, 10, 20],\n",
        "    \"clf__max_features\":     [\"sqrt\", \"log2\"],\n",
        "    \"clf__min_samples_split\":[2, 5],\n",
        "    \"clf__min_samples_leaf\": [1, 2]\n",
        "}\n",
        "\n",
        "# 3) RandomizedSearchCV â€“ just 30 draws instead of 720 fits\n",
        "et_rand = RandomizedSearchCV(\n",
        "    et_pipe,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=30,             # only 30 random combinations\n",
        "    scoring=\"roc_auc\",\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    random_state=RANDOM_STATE,\n",
        "    refit=True\n",
        ")\n",
        "\n",
        "# 4) Fit\n",
        "et_rand.fit(X_train, y_train)\n",
        "\n",
        "print(\"âœ… Best ExtraTrees params:\", et_rand.best_params_)\n",
        "print(\"âœ… Best CV AUC:         \", et_rand.best_score_)\n",
        "\n",
        "# 5) Save the params\n",
        "best_et_params = {\n",
        "    \"n_estimators\":     et_rand.best_params_[\"clf__n_estimators\"],\n",
        "    \"max_depth\":        et_rand.best_params_[\"clf__max_depth\"],\n",
        "    \"max_features\":     et_rand.best_params_[\"clf__max_features\"],\n",
        "    \"min_samples_split\":et_rand.best_params_[\"clf__min_samples_split\"],\n",
        "    \"min_samples_leaf\": et_rand.best_params_[\"clf__min_samples_leaf\"]\n",
        "}\n",
        "\n",
        "best_et_n      = best_et_params[\"n_estimators\"]\n",
        "best_et_depth  = best_et_params[\"max_depth\"]\n",
        "best_et_feats  = best_et_params[\"max_features\"]\n",
        "best_et_split  = best_et_params[\"min_samples_split\"]\n",
        "best_et_leaf   = best_et_params[\"min_samples_leaf\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MLC-7EkUo6Vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dced9032-86f9-4f84-9dda-eca074386958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
            "âœ… Best HistGB params: {'min_samples_leaf': 50, 'max_leaf_nodes': 15, 'max_iter': 200, 'max_depth': 5, 'learning_rate': 0.01, 'l2_regularization': 5.0} â†’ CV AUC: 0.702182861781076\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•¡ Cell 4.8 â€“ Randomized tune for HistGB with SMOTE â”€â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "from imblearn.pipeline      import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble       import HistGradientBoostingClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# 1) Pipeline: preprocess â†’ SMOTE â†’ HistGB\n",
        "hgb_pipe = ImbPipeline([\n",
        "    (\"prep\", preprocessor),\n",
        "    (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
        "    (\"clf\", HistGradientBoostingClassifier(\n",
        "        loss=\"log_loss\",\n",
        "        early_stopping=\"auto\",\n",
        "        validation_fraction=0.1,\n",
        "        n_iter_no_change=20,\n",
        "        random_state=RANDOM_STATE\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 2) A richer space\n",
        "param_dist = {\n",
        "    \"clf__learning_rate\":      [0.005, 0.01, 0.03, 0.05, 0.1],\n",
        "    \"clf__max_iter\":           [200, 500, 1000, 1500],\n",
        "    \"clf__max_depth\":          [None, 3, 5, 7],\n",
        "    \"clf__min_samples_leaf\":   [20, 50, 100],\n",
        "    \"clf__l2_regularization\":  [0.0, 0.1, 1.0, 5.0],\n",
        "    \"clf__max_leaf_nodes\":     [15, 31, 63]\n",
        "}\n",
        "\n",
        "# 3) RandomizedSearchCV â€“ 30 draws, 3-fold CV\n",
        "hgb_rand = RandomizedSearchCV(\n",
        "    hgb_pipe,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=30,\n",
        "    scoring=\"roc_auc\",\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    random_state=RANDOM_STATE,\n",
        "    refit=True\n",
        ")\n",
        "\n",
        "# 4) Fit it\n",
        "hgb_rand.fit(X_train, y_train)\n",
        "\n",
        "# 5) Capture the winner\n",
        "best_hgb_params = {\n",
        "    k.replace(\"clf__\", \"\"): v\n",
        "    for k, v in hgb_rand.best_params_.items()\n",
        "}\n",
        "print(\"âœ… Best HistGB params:\", best_hgb_params,\n",
        "      \"â†’ CV AUC:\", hgb_rand.best_score_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "A1B6O6HTjlM0"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 5 â€“ Build models dict with SMOTE in every pipeline â”€â•â•â•â•â•â•â•â•â•—\n",
        "from imblearn.pipeline       import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling  import SMOTE\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "import numpy as np\n",
        "\n",
        "models = {\n",
        "    \"LogReg\": RandomizedSearchCV(\n",
        "        ImbPipeline([\n",
        "            (\"prep\",  preprocessor),\n",
        "            (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
        "            (\"clf\",   LogisticRegression(\n",
        "                          solver=\"saga\",\n",
        "                          penalty=\"elasticnet\",\n",
        "                          l1_ratio=0.5,\n",
        "                          class_weight=\"balanced\",\n",
        "                          max_iter=5000,\n",
        "                          random_state=RANDOM_STATE\n",
        "                      ))\n",
        "        ]),\n",
        "        param_distributions={\n",
        "            \"clf__C\":        [1e-3, 1e-2, 1e-1, 1, 10, 100],\n",
        "            \"clf__l1_ratio\":[0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "        },\n",
        "        n_iter=20,\n",
        "        scoring=\"roc_auc\",\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        random_state=RANDOM_STATE,\n",
        "        refit=True\n",
        "    ),\n",
        "\n",
        "    \"SVM\": RandomizedSearchCV(\n",
        "        ImbPipeline([\n",
        "            (\"prep\",  preprocessor),\n",
        "            (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
        "            (\"clf\",   SVC(\n",
        "                          probability=True,\n",
        "                          kernel=\"rbf\",\n",
        "                          class_weight=\"balanced\",\n",
        "                          random_state=RANDOM_STATE\n",
        "                      ))\n",
        "        ]),\n",
        "        param_distributions={\n",
        "            \"clf__C\":     np.logspace(-3, 3, 20),\n",
        "            \"clf__gamma\": np.logspace(-4, 0, 20)\n",
        "        },\n",
        "        n_iter=30,\n",
        "        scoring=\"roc_auc\",\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        random_state=RANDOM_STATE,\n",
        "        refit=True\n",
        "    ),\n",
        "\n",
        "    \"NaiveBayes\": GridSearchCV(\n",
        "        ImbPipeline([\n",
        "            (\"prep\",  preprocessor),\n",
        "            (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
        "            (\"clf\",   GaussianNB())\n",
        "        ]),\n",
        "        param_grid={\"clf__var_smoothing\": np.logspace(-12, -6, 6)},\n",
        "        scoring=\"roc_auc\",\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        verbose=1,\n",
        "        refit=True\n",
        "    ),\n",
        "\n",
        "    \"ExtraTrees\": ImbPipeline([\n",
        "        (\"prep\",  preprocessor),\n",
        "        (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
        "        (\"clf\",   ExtraTreesClassifier(\n",
        "                      n_estimators=     best_et_n,\n",
        "                      max_depth=        best_et_depth,\n",
        "                      max_features=     best_et_feats,\n",
        "                      min_samples_split=best_et_split,\n",
        "                      min_samples_leaf= best_et_leaf,\n",
        "                      random_state=     RANDOM_STATE,\n",
        "                      class_weight=     \"balanced\",\n",
        "                      n_jobs=-1\n",
        "                  ))\n",
        "    ]),\n",
        "\n",
        "    \"HistGB\": ImbPipeline([\n",
        "        (\"prep\",  preprocessor),\n",
        "        (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
        "        (\"clf\",   HistGradientBoostingClassifier(\n",
        "                      loss=               \"log_loss\",\n",
        "                      learning_rate=      best_hgb_params[\"learning_rate\"],\n",
        "                      max_iter=           best_hgb_params[\"max_iter\"],\n",
        "                      max_depth=          best_hgb_params[\"max_depth\"],\n",
        "                      min_samples_leaf=   best_hgb_params[\"min_samples_leaf\"],\n",
        "                      l2_regularization=  best_hgb_params[\"l2_regularization\"],\n",
        "                      max_leaf_nodes=     best_hgb_params[\"max_leaf_nodes\"],\n",
        "                      early_stopping=     \"auto\",\n",
        "                      validation_fraction=0.1,\n",
        "                      n_iter_no_change=   20,\n",
        "                      random_state=       RANDOM_STATE\n",
        "                  ))\n",
        "    ])\n",
        "}\n",
        "\n",
        "# If you still need the cat_features_idx for SHAP or CatBoost elsewhere:\n",
        "cat_features_idx = [X_train.columns.get_loc(c) for c in cat]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•¡ Cell 5.1 â€“ Fullâ€train smoke test of all pipelines â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print(\"=== Pipeline structure ===\")\n",
        "for name, pipe in models.items():\n",
        "    print(f\"{name}:\")\n",
        "    if hasattr(pipe, \"steps\"):\n",
        "        print(\"  Steps:\", [step for step, _ in pipe.steps])\n",
        "    else:\n",
        "        print(\"  (not a pipeline!)\", type(pipe).__name__)\n",
        "    print()\n",
        "\n",
        "print(\"=== Smoke test (fit on full X_train, score on X_test) ===\")\n",
        "for name, pipe in models.items():\n",
        "    try:\n",
        "        pipe.fit(X_train, y_train)\n",
        "        probs = pipe.predict_proba(X_test)[:, 1]\n",
        "        auc = roc_auc_score(y_test, probs)\n",
        "        print(f\"{name}: âœ” fitted & predict_proba OK â†’ AUC on hold-out = {auc:.3f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"{name}: âœ– ERROR â†’ {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKCQsQFMIgVn",
        "outputId": "7e0dd475-3feb-4e45-f883-1c35b3080de5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Pipeline structure ===\n",
            "LogReg:\n",
            "  (not a pipeline!) RandomizedSearchCV\n",
            "\n",
            "SVM:\n",
            "  (not a pipeline!) RandomizedSearchCV\n",
            "\n",
            "NaiveBayes:\n",
            "  (not a pipeline!) GridSearchCV\n",
            "\n",
            "ExtraTrees:\n",
            "  Steps: ['prep', 'smote', 'clf']\n",
            "\n",
            "HistGB:\n",
            "  Steps: ['prep', 'smote', 'clf']\n",
            "\n",
            "=== Smoke test (fit on full X_train, score on X_test) ===\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "LogReg: âœ” fitted & predict_proba OK â†’ AUC on hold-out = 0.691\n",
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "SVM: âœ” fitted & predict_proba OK â†’ AUC on hold-out = 0.500\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "NaiveBayes: âœ” fitted & predict_proba OK â†’ AUC on hold-out = 0.642\n",
            "ExtraTrees: âœ” fitted & predict_proba OK â†’ AUC on hold-out = 0.565\n",
            "HistGB: âœ” fitted & predict_proba OK â†’ AUC on hold-out = 0.415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KvQoEpyqo8Ga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76128a03-39c1-4694-ed0d-1d00438ecaa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 15 folds for each of 10 candidates, totalling 150 fits\n",
            "âœ… Best CatBoost params: {'subsample': 0.8, 'learning_rate': 0.01, 'l2_leaf_reg': 5, 'iterations': 200, 'depth': 8, 'border_count': 128}\n",
            "âœ… Best CV AUC:         0.6433497536945811\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•¡ Cell 5.2 â€“ Tune CatBoost on raw data (no SMOTE) with repeated stratified CV â•â•â•â•â•â•â•â•â•â•â•—\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "# 1) Prepare your train DataFrame for CatBoost: fill NaNs in catâ€cols with \"Missing\" as strings\n",
        "X_train_cb = prepare_for_catboost(X_train, cat)\n",
        "\n",
        "# 2) Define base CatBoost and richer hyperparameter space\n",
        "cb = CatBoostClassifier(\n",
        "    loss_function=\"Logloss\",\n",
        "    eval_metric=\"AUC\",\n",
        "    random_seed=RANDOM_STATE,\n",
        "    verbose=False\n",
        ")\n",
        "param_dist = {\n",
        "    \"iterations\":    [200, 500, 1000],\n",
        "    \"depth\":         [4, 6, 8],\n",
        "    \"learning_rate\": [0.01, 0.03, 0.05, 0.1],\n",
        "    \"l2_leaf_reg\":   [1, 3, 5],\n",
        "    \"subsample\":     [0.6, 0.8, 1.0],\n",
        "    \"border_count\":  [32, 64, 128],\n",
        "}\n",
        "\n",
        "# 3) Repeated stratified K-fold for stability on imbalanced data\n",
        "rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=RANDOM_STATE)\n",
        "\n",
        "# 4) RandomizedSearchCV on the raw CatBoostClassifier\n",
        "rs_cb = RandomizedSearchCV(\n",
        "    cb,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,\n",
        "    scoring=\"roc_auc\",\n",
        "    cv=rskf,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    random_state=RANDOM_STATE,\n",
        "    refit=True\n",
        ")\n",
        "\n",
        "# 5) Fitâ€”but pass `cat_features` so CatBoost knows which cols are categorical\n",
        "rs_cb.fit(\n",
        "    X_train_cb,\n",
        "    y_train,\n",
        "    cat_features=cat_features_idx\n",
        ")\n",
        "\n",
        "print(\"âœ… Best CatBoost params:\", rs_cb.best_params_)\n",
        "print(\"âœ… Best CV AUC:        \", rs_cb.best_score_)\n",
        "\n",
        "# 6) Save the tuned CatBoostClassifier (bare, not wrapped in a pipeline)\n",
        "models[\"CatBoost\"] = rs_cb.best_estimator_\n",
        "\n",
        "# 7) (Re)compute your categoricalâ€feature indices for SHAP / Cell 6\n",
        "cat_features_idx = [X_train.columns.get_loc(c) for c in cat]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "14rvNrWpouj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed7c43a-3c38-4ecf-d1d2-0bb251106771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 9 folds for each of 50 candidates, totalling 450 fits\n",
            "âœ… Best AdaBoost params: {'clf__n_estimators': 800, 'clf__learning_rate': 1.0, 'clf__estimator__min_samples_split': 5, 'clf__estimator__min_samples_leaf': 2, 'clf__estimator__max_depth': 4, 'clf__algorithm': 'SAMME.R'}\n",
            "âœ… Best CV AUC:         0.6509954992097848\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•¡ Cell 5.3 â€“ Deep hyper-tuning AdaBoost with SMOTE & repeated stratified CV â•â•â•—\n",
        "from imblearn.pipeline            import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling       import SMOTE\n",
        "from sklearn.tree                 import DecisionTreeClassifier\n",
        "from sklearn.ensemble             import AdaBoostClassifier\n",
        "from sklearn.model_selection      import RandomizedSearchCV, RepeatedStratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "# 1) Pipeline: preprocess â†’ SMOTE â†’ AdaBoost(with explicit base tree)\n",
        "ab_pipe = ImbPipeline([\n",
        "    (\"prep\",  preprocessor),\n",
        "    (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
        "    (\"clf\",   AdaBoostClassifier(\n",
        "                  estimator=DecisionTreeClassifier(\n",
        "                      random_state=RANDOM_STATE\n",
        "                  ),\n",
        "                  random_state=RANDOM_STATE\n",
        "              ))\n",
        "])\n",
        "\n",
        "# 2) A richer Randomized grid\n",
        "param_dist = {\n",
        "    \"clf__n_estimators\":                [50, 100, 200, 400, 800],\n",
        "    \"clf__learning_rate\":               [0.01, 0.05, 0.1, 0.5, 1.0],\n",
        "    \"clf__algorithm\":                   [\"SAMME\", \"SAMME.R\"],\n",
        "    \"clf__estimator__max_depth\":        [1, 2, 3, 4, None],\n",
        "    \"clf__estimator__min_samples_split\":[2, 5, 10],\n",
        "    \"clf__estimator__min_samples_leaf\": [1, 2, 4]\n",
        "}\n",
        "\n",
        "# 3) Repeated stratified K-fold\n",
        "rskf = RepeatedStratifiedKFold(\n",
        "    n_splits=3,\n",
        "    n_repeats=3,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# 4) RandomizedSearchCV\n",
        "ab_search = RandomizedSearchCV(\n",
        "    ab_pipe,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,                # 50 random draws\n",
        "    scoring=\"roc_auc\",\n",
        "    cv=rskf,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    random_state=RANDOM_STATE,\n",
        "    refit=True\n",
        ")\n",
        "\n",
        "# 5) Fit on your build set\n",
        "ab_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"âœ… Best AdaBoost params:\", ab_search.best_params_)\n",
        "print(\"âœ… Best CV AUC:        \", ab_search.best_score_)\n",
        "\n",
        "# 6) Store the tuned pipeline\n",
        "models[\"AdaBoost\"] = ab_search.best_estimator_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "V_FbAFdsnjqz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a22c69da-39ec-44e1-b67e-6a411033fdf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [10:51:22] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/callback.py:386: UserWarning: [10:51:22] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  self.starting_round = model.num_boosted_rounds()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Best XGB params: {'clf__subsample': 0.8, 'clf__reg_lambda': 10, 'clf__reg_alpha': 1, 'clf__n_estimators': 300, 'clf__max_depth': 3, 'clf__learning_rate': 0.03, 'clf__gamma': 0, 'clf__colsample_bytree': 1.0}\n",
            "âœ… Best CV AUC:    0.6483579638752053\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•¡ Cell 5.4 â€“ Enhanced Randomized search â†’ final XGBoost â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "import xgboost as xgb\n",
        "from sklearn.pipeline        import Pipeline\n",
        "from sklearn.impute          import SimpleImputer\n",
        "from sklearn.preprocessing   import OrdinalEncoder\n",
        "from sklearn.compose         import ColumnTransformer\n",
        "from sklearn.model_selection import RandomizedSearchCV, RepeatedStratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "# 1) Simple preprocessor\n",
        "num_imp     = SimpleImputer(strategy=\"median\")\n",
        "cat_imp_enc = Pipeline([\n",
        "    (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=-1)),\n",
        "    (\"encode\", OrdinalEncoder(\n",
        "         handle_unknown=\"use_encoded_value\",\n",
        "         unknown_value=-1\n",
        "    ))\n",
        "])\n",
        "pre_xgb = ColumnTransformer([\n",
        "    (\"num\", num_imp, cont),\n",
        "    (\"cat\", cat_imp_enc, cat)\n",
        "], remainder=\"drop\")\n",
        "\n",
        "# 2) Base pipeline (no early stopping in CV)\n",
        "xgb_pipe = Pipeline([\n",
        "    (\"pre\", pre_xgb),\n",
        "    (\"clf\", xgb.XGBClassifier(\n",
        "        objective=\"binary:logistic\",\n",
        "        eval_metric=\"auc\",\n",
        "        tree_method=\"hist\",\n",
        "        scale_pos_weight=(y_train==0).sum()/(y_train==1).sum(),\n",
        "        random_state=RANDOM_STATE,\n",
        "        use_label_encoder=False\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 3) Expanded random search space\n",
        "param_dist = {\n",
        "    \"clf__n_estimators\":    [100, 300, 600, 1000],\n",
        "    \"clf__max_depth\":       [3, 5, 7, 9],\n",
        "    \"clf__learning_rate\":   [0.001, 0.01, 0.03, 0.1],\n",
        "    \"clf__subsample\":       [0.6, 0.8, 1.0],\n",
        "    \"clf__colsample_bytree\":[0.6, 0.8, 1.0],\n",
        "    \"clf__gamma\":           [0, 1, 5],\n",
        "    \"clf__reg_alpha\":       [0, 0.1, 1],\n",
        "    \"clf__reg_lambda\":      [1, 5, 10]\n",
        "}\n",
        "\n",
        "# 4) Use repeated stratified CV for more stable estimates\n",
        "rsk = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=RANDOM_STATE)\n",
        "\n",
        "rs_xgb = RandomizedSearchCV(\n",
        "    xgb_pipe,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,\n",
        "    scoring=\"roc_auc\",\n",
        "    cv=rsk,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    random_state=RANDOM_STATE,\n",
        "    refit=True\n",
        ")\n",
        "\n",
        "# 5) Run the search\n",
        "rs_xgb.fit(X_train, y_train)\n",
        "\n",
        "print(\"âœ… Best XGB params:\", rs_xgb.best_params_)\n",
        "print(\"âœ… Best CV AUC:   \", rs_xgb.best_score_)\n",
        "\n",
        "# 6) Build final XGB with early stopping on your temporal hold-out\n",
        "best_params = {\n",
        "    k.replace(\"clf__\", \"\"): v\n",
        "    for k, v in rs_xgb.best_params_.items()\n",
        "}\n",
        "xgb_final = xgb.XGBClassifier(\n",
        "    **best_params,\n",
        "    objective=\"binary:logistic\",\n",
        "    eval_metric=\"auc\",\n",
        "    tree_method=\"hist\",\n",
        "    scale_pos_weight=(y_train==0).sum()/(y_train==1).sum(),\n",
        "    early_stopping_rounds=30,\n",
        "    random_state=RANDOM_STATE,\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "# 7) Fit the preprocessor & transform both build and hold-out\n",
        "pre_xgb.fit(X_train)\n",
        "X_tr = pre_xgb.transform(X_train)\n",
        "X_te = pre_xgb.transform(X_test)\n",
        "\n",
        "# 8) Train with early stopping on the test slice\n",
        "xgb_final.fit(\n",
        "    X_tr, y_train,\n",
        "    eval_set=[(X_te, y_test)],\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# 9) Save the pipeline for downstream use\n",
        "models[\"XGBoost\"] = Pipeline([(\"pre\", pre_xgb), (\"clf\", xgb_final)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-1p3iHnqjm3C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "b946d3e2-574a-4f80-92d7-bca6dc16fc50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fold 1 ---\n",
            "LogReg       AUC = 0.576\n",
            "SVM          AUC = 0.424\n",
            "NaiveBayes   AUC = 0.416\n",
            "ExtraTrees   AUC = 0.562\n",
            "HistGB       AUC = 0.626\n",
            "CatBoost     AUC = 0.660\n",
            "AdaBoost     AUC = 0.709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/callback.py:386: UserWarning: [10:51:31] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  self.starting_round = model.num_boosted_rounds()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Must have at least 1 validation dataset for early stopping.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-4a5a548b89b4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfull_pipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m                       \u001b[0;31m# pipeline does preprocâ†’SMOTEâ†’clf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0my_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# pipeline handles transform + predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1472\u001b[0m                 )\n\u001b[1;32m   1473\u001b[0m             ):\n\u001b[0;32m-> 1474\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m                 \u001b[0mlast_step_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrouted_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlast_step_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1680\u001b[0m             )\n\u001b[1;32m   1681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1683\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mmetric_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_eval_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/callback.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mmetric_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_eval_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/xgboost/callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[0;34m(self, model, epoch, evals_log)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Must have at least 1 validation dataset for early stopping.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;31m# Get data name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Must have at least 1 validation dataset for early stopping."
          ]
        }
      ],
      "source": [
        "# â•”â•â•¡ Cell 6 â€“ 80/20 StratifiedShuffleSplit ROC (mean Â± std) with SMOTE (except CatBoost) â”€â•â•â•â•â•—\n",
        "import numpy as np\n",
        "from sklearn.model_selection   import StratifiedShuffleSplit\n",
        "from sklearn.metrics           import roc_curve, roc_auc_score, RocCurveDisplay\n",
        "from sklearn.base              import clone\n",
        "from imblearn.over_sampling     import SMOTE\n",
        "from imblearn.pipeline          import Pipeline as ImbPipeline\n",
        "from sklearn.pipeline           import Pipeline as SkPipeline\n",
        "\n",
        "# 1) Build â€œfullâ€ pipelines for every model, but skip SMOTE for CatBoost\n",
        "full_pipes = {}\n",
        "for name, mdl in models.items():\n",
        "    # unwrap CV wrappers if present\n",
        "    pipe = mdl.best_estimator_ if hasattr(mdl, \"best_estimator_\") else mdl\n",
        "\n",
        "    if isinstance(pipe, (SkPipeline, ImbPipeline)):\n",
        "        # already a pipeline: leave as-is\n",
        "        full_pipes[name] = pipe\n",
        "\n",
        "    else:\n",
        "        # bare estimator: wrap with preprocessor + (optional SMOTE) + clf\n",
        "        steps = [(\"prep\", preprocessor)]\n",
        "        if name != \"CatBoost\":\n",
        "            steps.append((\"smote\", SMOTE(random_state=RANDOM_STATE)))\n",
        "        steps.append((\"clf\", pipe))\n",
        "        full_pipes[name] = SkPipeline(steps) if name == \"CatBoost\" else ImbPipeline(steps)\n",
        "\n",
        "# 2) Prepare 5Ã—80/20 stratified splits\n",
        "sss       = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=RANDOM_STATE)\n",
        "mean_fpr  = np.linspace(0, 1, 200)\n",
        "aucs      = {n: [] for n in full_pipes}\n",
        "mean_tpr  = {n: np.zeros_like(mean_fpr) for n in full_pipes}\n",
        "\n",
        "# 3) Loop folds, clone & fit each full pipeline\n",
        "for fold, (tr_idx, val_idx) in enumerate(sss.split(X_train, y_train), start=1):\n",
        "    X_tr, X_val = X_train.iloc[tr_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train.iloc[tr_idx], y_train.iloc[val_idx]\n",
        "    print(f\"\\n--- Fold {fold} ---\")\n",
        "    for name, pipe in full_pipes.items():\n",
        "        clf = clone(pipe)\n",
        "        clf.fit(X_tr, y_tr)                       # pipeline does prepâ†’[SMOTE]â†’clf\n",
        "        y_prob = clf.predict_proba(X_val)[:, 1]\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(y_val, y_prob)\n",
        "        auc_score   = roc_auc_score(y_val, y_prob)\n",
        "        aucs[name].append(auc_score)\n",
        "        mean_tpr[name] += np.interp(mean_fpr, fpr, tpr)\n",
        "        print(f\"{name:12s} AUC = {auc_score:.3f}\")\n",
        "\n",
        "# 4) Summarize perâ€fold AUCs\n",
        "print(\"\\n=== Summary of perâ€fold AUCs ===\")\n",
        "for name, scores in aucs.items():\n",
        "    m, s = np.mean(scores), np.std(scores)\n",
        "    print(f\"{name:12s}: {['{:.3f}'.format(x) for x in scores]} â†’ {m:.3f}Â±{s:.3f}\")\n",
        "\n",
        "# 5) Build averaged ROC displays for Cell 7\n",
        "roc_displays = []\n",
        "for name in full_pipes:\n",
        "    mean_tpr[name] /= sss.get_n_splits()\n",
        "    mean_tpr[name][0], mean_tpr[name][-1] = 0.0, 1.0\n",
        "    m, s = np.mean(aucs[name]), np.std(aucs[name])\n",
        "    roc_displays.append(\n",
        "        RocCurveDisplay(\n",
        "            fpr=mean_fpr,\n",
        "            tpr=mean_tpr[name],\n",
        "            estimator_name=f\"{name} (AUC={m:.3f}Â±{s:.3f})\"\n",
        "        )\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZiaxyy-joWW"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 7 â€“ Plot combined ROC figure â”€â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
        "\n",
        "for idx, disp in enumerate(roc_displays):\n",
        "    disp.plot(ax=plt.gca(), alpha=0.85, linewidth=2, color=colors[idx % len(colors)])\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"--\", color=\"grey\", linewidth=1)\n",
        "plt.title(\"ROC â€“ Recurrence_2yr\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9AAvf6fRV0q"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 7b â€“ Bootstrap AUC 95% CI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•—\n",
        "import numpy as np\n",
        "from sklearn.metrics    import roc_auc_score\n",
        "\n",
        "# 1) ground truth\n",
        "y_true = y_test.reset_index(drop=True)\n",
        "\n",
        "# 2) pipeline handles preprocessing internally\n",
        "y_prob = models[\"XGBoost\"].predict_proba(\n",
        "    X_test.reset_index(drop=True)\n",
        ")[:, 1]\n",
        "\n",
        "# 3) bootstrap\n",
        "n_bootstraps = 1000\n",
        "rng = np.random.RandomState(42)\n",
        "scores = []\n",
        "\n",
        "for _ in range(n_bootstraps):\n",
        "    idx = rng.randint(0, len(y_true), len(y_true))\n",
        "    if len(np.unique(y_true.iloc[idx])) < 2:\n",
        "        continue\n",
        "    scores.append(roc_auc_score(y_true.iloc[idx], y_prob[idx]))\n",
        "\n",
        "ci_lower, ci_upper = np.percentile(scores, [2.5, 97.5])\n",
        "auc_mean = roc_auc_score(y_true, y_prob)\n",
        "\n",
        "print(f\"AUC (test)         = {auc_mean:.3f}\")\n",
        "print(f\"95% CI (bootstrap)= [{ci_lower:.3f}, {ci_upper:.3f}]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Iwf0lehjq6_"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 8 â€“ Bar chart of mean ShuffleSplit AUCs with Â±std â”€â•â•â•â•â•â•â•â•â•—\n",
        "import numpy as np\n",
        "\n",
        "# 1. Compute mean & std per model\n",
        "mean_aucs = {name: np.mean(vals) for name, vals in aucs.items()}\n",
        "std_aucs  = {name: np.std(vals)  for name, vals in aucs.items()}\n",
        "\n",
        "# 2. Sort by mean AUC\n",
        "sorted_items = sorted(mean_aucs.items(), key=lambda kv: kv[1])\n",
        "labels, means = zip(*sorted_items)\n",
        "stds = [std_aucs[name] for name in labels]\n",
        "\n",
        "# 3. Plot bars with error bars\n",
        "plt.figure(figsize=(10, 4))\n",
        "bars = plt.bar(labels, means, yerr=stds, capsize=4)\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel(\"Mean AUC\")\n",
        "plt.title(\"Mean AUC Â± Std â€“ 80/20 ShuffleSplit (5 runs)\")\n",
        "plt.xticks(rotation=30, ha=\"right\")\n",
        "\n",
        "# 4. Annotate each bar with meanÂ±std\n",
        "for bar, m, s in zip(bars, means, stds):\n",
        "    text = f\"{m:.3f}Â±{s:.3f}\"\n",
        "    plt.annotate(\n",
        "        text,\n",
        "        xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
        "        xytext=(0, 3), textcoords=\"offset points\",\n",
        "        ha=\"center\", va=\"bottom\", fontsize=8\n",
        "    )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6w9OoFOjp4L"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 9 â€“ Quick summary table with mean Â± std AUC â”€â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "import numpy as np\n",
        "\n",
        "# Build a list of records\n",
        "records = []\n",
        "for name, vals in aucs.items():\n",
        "    records.append({\n",
        "        \"Model\":    name,\n",
        "        \"Mean AUC\": np.mean(vals),\n",
        "        \"Std AUC\":  np.std(vals)\n",
        "    })\n",
        "\n",
        "# Create DataFrame and sort\n",
        "summary = (\n",
        "    pd.DataFrame(records)\n",
        "      .sort_values(\"Mean AUC\", ascending=False)\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# Plainâ€text print\n",
        "print(summary.to_string(index=False, float_format=\"%.3f\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eY9chGwXLmvL"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 10.1 â€“ Pipeline + sigmoid calibration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•—\n",
        "from sklearn.pipeline            import Pipeline\n",
        "from sklearn.calibration        import CalibratedClassifierCV\n",
        "from xgboost                    import XGBClassifier\n",
        "\n",
        "# 1) Build an XGB pipeline WITHOUT early stopping\n",
        "#    This uses the same hyperparameters you found in Cell 5.4 (best_params).\n",
        "xgb_pipe_uncal = Pipeline([\n",
        "    (\"prep\", pre_xgb),  # your simple medianâ€imputer + ordinalâ€encoder ColumnTransformer\n",
        "    (\"clf\",  XGBClassifier(\n",
        "        **best_params,               # from your RandomizedSearchCV in Cell 5.4\n",
        "        objective=\"binary:logistic\",\n",
        "        eval_metric=\"auc\",\n",
        "        tree_method=\"hist\",\n",
        "        scale_pos_weight=(y_train==0).sum()/(y_train==1).sum(),\n",
        "        random_state=RANDOM_STATE\n",
        "        # <â€” NO early_stopping_rounds here!\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 2) Wrap in a Plattâ€scaler (sigmoid) using 5â€fold CV on the full training set\n",
        "calibrator = CalibratedClassifierCV(\n",
        "    estimator=xgb_pipe_uncal,\n",
        "    method=\"sigmoid\",  # Platt scaling\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# 3) Fit on your entire training set\n",
        "calibrator.fit(X_train, y_train)\n",
        "\n",
        "# 4) Store back into your models dict\n",
        "models[\"XGBoost_Calibrated\"] = calibrator\n",
        "\n",
        "print(\"âœ… Calibrated XGBoost fitted with sigmoid scaling (5â€fold CV).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSquBqE3I32F"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 10.2 â€“ Calibration curve + Brier score â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•â•â•â•â•â•â•—\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics      import brier_score_loss\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Raw probabilities (before calibration) on the raw X_test\n",
        "y_prob_raw = models[\"XGBoost\"].predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 2) Calibrated probabilities (same raw X_test)\n",
        "y_prob_cal = models[\"XGBoost_Calibrated\"].predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 3) Compute calibration curves (fraction of positives vs. mean predicted)\n",
        "frac_pos_raw, mean_pred_raw = calibration_curve(y_test, y_prob_raw, n_bins=10)\n",
        "frac_pos_cal, mean_pred_cal = calibration_curve(y_test, y_prob_cal, n_bins=10)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(mean_pred_raw, frac_pos_raw, \"s-\", label=\"XGBoost (raw)\")\n",
        "plt.plot(mean_pred_cal, frac_pos_cal, \"o-\", label=\"XGBoost (calibrated)\")\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfectly calibrated\")\n",
        "plt.xlabel(\"Mean predicted probability\")\n",
        "plt.ylabel(\"Fraction of positives\")\n",
        "plt.title(\"Calibration curve â€“ XGBoost\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4) Brier scores for raw vs. calibrated\n",
        "print(\"Brier score (raw)     :\", brier_score_loss(y_test, y_prob_raw))\n",
        "print(\"Brier score (calibr.) :\", brier_score_loss(y_test, y_prob_cal))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Bz5CwvWJBRd"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 10.3 â€“ Precisionâ€“Recall & thresholdâ€tuning â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "from sklearn.metrics import precision_recall_curve, f1_score\n",
        "\n",
        "y_prob = models[\"XGBoost\"].predict_proba(X_test)[:,1]\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(recall, precision, label=\"XGBoost PR-curve\")\n",
        "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precisionâ€“Recall curve\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# F1 vs threshold\n",
        "f1s = [f1_score(y_test, y_prob>=t) for t in thresholds]\n",
        "opt_idx = np.argmax(f1s)\n",
        "print(f\"Best F1={f1s[opt_idx]:.3f} at threshold={thresholds[opt_idx]:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2V_vAecBU8TX"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 10.4 â€“ SHAP summary (model-agnostic) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•â•â•â•â•â•â•—\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Make a simple function that takes a DataFrame X and returns P(y=1)\n",
        "def model_proba(df):\n",
        "    return models[\"XGBoost\"].predict_proba(df)[:, 1]\n",
        "\n",
        "# 2) Build the explainer on your training DataFrame\n",
        "explainer = shap.Explainer(model_proba, X_train)\n",
        "\n",
        "# 3) Compute SHAP values on your held-out test set\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "# 4) Beeswarm (dot) summary\n",
        "plt.figure(figsize=(10, 6))\n",
        "shap.plots.beeswarm(shap_values, max_display=20, show=False)\n",
        "plt.title(\"SHAP Beeswarm â€“ XGBoost (Recurrence_2yr)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 5) Bar plot of mean(|SHAP|)\n",
        "plt.figure(figsize=(6, 8))\n",
        "shap.plots.bar(shap_values, max_display=20, show=False)\n",
        "plt.title(\"mean(|SHAP|) â€“ XGBoost\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1smZQNICJKPL"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 10.5 â€“ Partial dependence for top features â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "import numpy as np\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Extract the raw SHAP values array from the Explanation\n",
        "#    shap_values was created in Cell 10 via `explainer(X_test)`\n",
        "vals = shap_values.values\n",
        "# If itâ€™s a 3â€D array (n_samples x 2 classes x n_features),\n",
        "# pick the positiveâ€class slice:\n",
        "if vals.ndim == 3:\n",
        "    vals = vals[:, 1, :]\n",
        "\n",
        "# 2) Compute mean(|SHAP|) per feature and grab top-3 indices\n",
        "importances = np.abs(vals).mean(axis=0)\n",
        "top_idx    = np.argsort(importances)[::-1][:3]\n",
        "top_feats  = [X_test.columns[i] for i in top_idx]\n",
        "\n",
        "print(\"Top 3 features by |SHAP|:\", top_feats)\n",
        "\n",
        "# 3) Plot partial dependence for those top 3\n",
        "fig, axes = plt.subplots(1, len(top_feats), figsize=(4*len(top_feats), 4))\n",
        "PartialDependenceDisplay.from_estimator(\n",
        "    models[\"XGBoost\"],\n",
        "    X_test,\n",
        "    features=top_feats,\n",
        "    ax=axes\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blQhd6RJJOxU"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 10.6 â€“ Permutation importance â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "r = permutation_importance(\n",
        "    models[\"XGBoost\"], X_test, y_test,\n",
        "    scoring=\"roc_auc\", n_repeats=10, random_state=RANDOM_STATE\n",
        ")\n",
        "perm_df = pd.Series(r.importances_mean, index=X_test.columns).sort_values(ascending=False)\n",
        "perm_df.head(10).plot.barh()\n",
        "plt.xlabel(\"Mean decrease in AUC\")\n",
        "plt.title(\"Permutation importance â€“ XGBoost\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WVg9QelJVSw"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 10.7 â€“ Manual Decision Curve Analysis (Net Benefit) â”€â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) True labels & predicted probabilities (from your best model)\n",
        "y_true = y_test.values        # shape (n_samples,)\n",
        "y_prob = models[\"XGBoost\"].predict_proba(X_test)[:,1]\n",
        "\n",
        "N      = len(y_true)\n",
        "preval = y_true.mean()        # event rate\n",
        "\n",
        "# 2) Define a grid of thresholds\n",
        "thresholds = np.linspace(0.01, 0.99, 99)\n",
        "\n",
        "# 3) Compute net benefit for each threshold\n",
        "nb_model = []\n",
        "nb_all   = []\n",
        "nb_none  = np.zeros_like(thresholds)\n",
        "\n",
        "for pt in thresholds:\n",
        "    preds = (y_prob >= pt).astype(int)\n",
        "    TP    = ((preds == 1) & (y_true == 1)).sum()\n",
        "    FP    = ((preds == 1) & (y_true == 0)).sum()\n",
        "    # NB = TP/N - FP/N * (pt/(1-pt))\n",
        "    nb    = TP/N - FP/N * (pt/(1-pt))\n",
        "    nb_model.append(nb)\n",
        "    nb_all.append(preval - (1 - preval)*(pt/(1-pt)))\n",
        "\n",
        "# 4) Plot\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(thresholds, nb_model, label=\"XGBoost\")\n",
        "plt.plot(thresholds, nb_all,   label=\"Treat All\",    linestyle=\"--\")\n",
        "plt.plot(thresholds, nb_none,  label=\"Treat None\",   linestyle=\":\")\n",
        "plt.xlabel(\"Decision Threshold\")\n",
        "plt.ylabel(\"Net Benefit\")\n",
        "plt.title(\"Decision Curve Analysis â€“ Recurrence_2yr\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•¡ Cell 10.8 â€“ Final evaluation on future holdâ€out â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "from sklearn.metrics       import (\n",
        "    roc_auc_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    RocCurveDisplay,\n",
        "    brier_score_loss,\n",
        "    roc_curve\n",
        ")\n",
        "from sklearn.calibration   import calibration_curve\n",
        "import matplotlib.pyplot   as plt\n",
        "import numpy              as np\n",
        "\n",
        "# 1) Pick your final model\n",
        "best_model    = models[\"XGBoost\"]    # or \"XGBoost_Calibrated\"\n",
        "X_val, y_val  = X_test, y_test\n",
        "\n",
        "# 2) Predicted probabilities & hard labels\n",
        "y_val_proba = best_model.predict_proba(X_val)[:, 1]\n",
        "y_val_pred  = best_model.predict(X_val)\n",
        "\n",
        "# 3) Print metrics\n",
        "print(\"Final AUC:            \", roc_auc_score(y_val, y_val_proba))\n",
        "print(\"Confusion matrix (0.5):\\n\", confusion_matrix(y_val, y_val_pred))\n",
        "print(\"\\nClassification report:\\n\", classification_report(y_val, y_val_pred))\n",
        "\n",
        "# 4) ROC curve\n",
        "RocCurveDisplay.from_predictions(y_val, y_val_proba)\n",
        "plt.title(\"Final ROC on holdâ€out\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 5) Calibration curve & Brier score\n",
        "frac_pos, mean_pred = calibration_curve(y_val, y_val_proba, n_bins=10)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(mean_pred, frac_pos, \"o-\", label=\"XGB holdâ€out\")\n",
        "plt.plot([0, 1], [0, 1], \"k--\",  label=\"Perfectly calibrated\")\n",
        "plt.xlabel(\"Mean predicted probability\")\n",
        "plt.ylabel(\"Fraction of positives\")\n",
        "plt.title(\"Calibration curve â€“ holdâ€out\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Final Brier score:\", brier_score_loss(y_val, y_val_proba))\n",
        "\n",
        "# 6) Optimal threshold via Youdenâ€™s J\n",
        "fpr, tpr, thresh = roc_curve(y_val, y_val_proba)\n",
        "j_scores         = tpr - fpr\n",
        "best_thresh      = thresh[np.argmax(j_scores)]\n",
        "print(f\"Optimal threshold (max Youden's J): {best_thresh:.3f}\")\n"
      ],
      "metadata": {
        "id": "cGbOlVkPZFsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•¡ Cell 10.9 â€“ Bootstrapâ€Calibrated XGBoost on future holdâ€out â•â•â•â•â•â•â•â•â•â•—\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.utils           import resample\n",
        "from sklearn.base            import clone\n",
        "from sklearn.metrics         import (\n",
        "    roc_auc_score, roc_curve,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    RocCurveDisplay,\n",
        "    brier_score_loss\n",
        ")\n",
        "from sklearn.calibration     import CalibratedClassifierCV\n",
        "\n",
        "# 1) Number of bootstrap replicates\n",
        "n_boot = 20\n",
        "\n",
        "# 2) Prepare array to hold each replicateâ€™s holdâ€out probs\n",
        "boot_preds = np.zeros((len(X_test), n_boot))\n",
        "\n",
        "# 3) Loop: bootstrap sample â†’ clone uncalibrated pipeline â†’ calibrate â†’ predict\n",
        "for i in range(n_boot):\n",
        "    # a) draw a bootstrap sample from your build set\n",
        "    Xb, yb = resample(X_train, y_train, random_state=RANDOM_STATE + i)\n",
        "    # b) clone the UNCALIBRATED XGB pipeline you built in Cell 10.1\n",
        "    xgb_pipe = clone(xgb_pipe_uncal)  # <-- no early stopping here!\n",
        "    # c) wrap in a Plattâ€scaler (sigmoid) calibrator\n",
        "    calib = CalibratedClassifierCV(\n",
        "        estimator=xgb_pipe,\n",
        "        method=\"sigmoid\",\n",
        "        cv=3\n",
        "    )\n",
        "    # d) fit on the bootstrap draw\n",
        "    calib.fit(Xb, yb)\n",
        "    # e) predict probabilities on the true 20% holdâ€out\n",
        "    boot_preds[:, i] = calib.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 4) average the bootstrapâ€calibrated probabilities\n",
        "y_mean = boot_preds.mean(axis=1)\n",
        "y_pred = (y_mean >= 0.5).astype(int)\n",
        "\n",
        "# 5) Discrimination & classification metrics\n",
        "print(\"Bootstrapâ€Calibrated XGBoost AUC:   \",\n",
        "      roc_auc_score(y_test, y_mean))\n",
        "print(\"Confusion matrix @0.5:\\n\",\n",
        "      confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification report:\\n\",\n",
        "      classification_report(y_test, y_pred))\n",
        "\n",
        "# 6) Plot ROC\n",
        "RocCurveDisplay.from_predictions(y_test, y_mean)\n",
        "plt.title(\"Bootstrapâ€Calibrated XGBoost â€“ ROC on holdâ€out\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 7) Calibration curve + Brier score\n",
        "from sklearn.calibration import calibration_curve\n",
        "frac_pos, mean_pred = calibration_curve(y_test, y_mean, n_bins=10)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(mean_pred, frac_pos, \"o-\", label=\"Bootâ€Calibrated XGB\")\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfectly calibrated\")\n",
        "plt.xlabel(\"Mean predicted probability\")\n",
        "plt.ylabel(\"Fraction of positives\")\n",
        "plt.title(\"Calibration curve â€“ holdâ€out\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Bootstrapâ€Calibrated XGB Brier score:\",\n",
        "      brier_score_loss(y_test, y_mean))\n",
        "\n",
        "# 8) Optimal threshold via Youdenâ€™s J\n",
        "fpr, tpr, thresh = roc_curve(y_test, y_mean)\n",
        "j_scores       = tpr - fpr\n",
        "best_thresh    = thresh[np.argmax(j_scores)]\n",
        "print(f\"Optimal threshold (max Youdenâ€™s J): {best_thresh:.3f}\")\n"
      ],
      "metadata": {
        "id": "hwyoFlSvn7TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-7GFSRefJ0e"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 11.0 â€“ SHAP summary for CatBoost (Recurrence_2yr) â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline as SkPipeline\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "# 1) Unpack your CatBoost model + preprocessor\n",
        "cb_entry = models[\"CatBoost\"]\n",
        "if isinstance(cb_entry, (SkPipeline, ImbPipeline)):\n",
        "    prep     = cb_entry.named_steps[\"prep\"]\n",
        "    cb_model = cb_entry.named_steps[\"clf\"]\n",
        "else:\n",
        "    prep     = preprocessor      # fallback to your ColumnTransformer\n",
        "    cb_model = cb_entry          # bare CatBoostClassifier\n",
        "\n",
        "# 2) Transform to the numeric matrix CatBoost was trained on\n",
        "X_train_pre = prep.transform(X_train)\n",
        "X_test_pre  = prep.transform(X_test)\n",
        "\n",
        "# 3) Build a TreeExplainer\n",
        "explainer_cb = shap.TreeExplainer(cb_model, X_train_pre)\n",
        "\n",
        "# 4) Compute SHAP values on your hold-out\n",
        "shap_values_cb = explainer_cb.shap_values(X_test_pre)\n",
        "print(\"ðŸ”Ž SHAP values shape:\", np.array(shap_values_cb).shape)\n",
        "\n",
        "# 5) Reconstruct feature names: continuous + one-hot cats\n",
        "ohe            = prep.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
        "cat_ohe_names  = ohe.get_feature_names_out(cat)\n",
        "feat_names     = cont + list(cat_ohe_names)\n",
        "\n",
        "# 6) Beeswarm (dot) summary plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "shap.summary_plot(\n",
        "    shap_values_cb,\n",
        "    X_test_pre,\n",
        "    feature_names=feat_names,\n",
        "    max_display=20,\n",
        "    show=False\n",
        ")\n",
        "plt.title(\"SHAP Beeswarm â€“ CatBoost (Recurrence_2yr)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 7) Bar plot of mean(|SHAP|)\n",
        "plt.figure(figsize=(6, 8))\n",
        "shap.summary_plot(\n",
        "    shap_values_cb,\n",
        "    X_test_pre,\n",
        "    feature_names=feat_names,\n",
        "    plot_type=\"bar\",\n",
        "    max_display=20,\n",
        "    show=False\n",
        ")\n",
        "plt.title(\"mean(|SHAP|) â€“ CatBoost\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_pdzzce-T8p"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 11.1 â€“ Partial dependence (top 3 preprocessed features) â•â•â•â•â•â•â•â•â•â•—\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Unpack your CatBoost pipeline or raw model\n",
        "cb_entry = models[\"CatBoost\"]\n",
        "if isinstance(cb_entry, (SkPipeline, ImbPipeline)):\n",
        "    prep     = cb_entry.named_steps[\"prep\"]\n",
        "    cb_model = cb_entry.named_steps[\"clf\"]\n",
        "else:\n",
        "    prep     = preprocessor\n",
        "    cb_model = cb_entry\n",
        "\n",
        "# 2) Preprocess your training set into the numeric array\n",
        "X_train_pre = prep.transform(X_train)\n",
        "\n",
        "# 3) Reconstruct the output feature names (cont + one-hot cats)\n",
        "ohe            = prep.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
        "cat_ohe_names  = ohe.get_feature_names_out(cat)\n",
        "feat_names     = cont + list(cat_ohe_names)\n",
        "\n",
        "# 4) Compute mean(|SHAP|) per preâ€processed feature and grab top 3 indices\n",
        "mean_abs_shap = np.abs(shap_values_cb).mean(axis=0)\n",
        "top3_idx      = np.argsort(mean_abs_shap)[-3:]\n",
        "\n",
        "# 5) Plot partial dependence for the top 3\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "PartialDependenceDisplay.from_estimator(\n",
        "    cb_model,\n",
        "    X_train_pre,\n",
        "    features=list(top3_idx),    # integer indices into your preprocessed matrix\n",
        "    feature_names=feat_names,   # labels for each column\n",
        "    grid_resolution=50,\n",
        "    ax=axes\n",
        ")\n",
        "plt.suptitle(\"Partial Dependence â€“ CatBoost (top 3 features)\", y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkYcNh6e-VfF"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 11.2 â€“ Permutation importance (CatBoost) â”€â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "from sklearn.inspection import permutation_importance\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Figure out where the preprocessor & model live:\n",
        "cb_pipe_candidate = models[\"CatBoost\"]\n",
        "if hasattr(cb_pipe_candidate, \"named_steps\"):\n",
        "    # itâ€™s a Pipeline(prep â†’ clf)\n",
        "    prep     = cb_pipe_candidate.named_steps[\"prep\"]\n",
        "    cb_model = cb_pipe_candidate.named_steps[\"clf\"]\n",
        "else:\n",
        "    # itâ€™s a bare CatBoostClassifier\n",
        "    prep     = preprocessor\n",
        "    cb_model = cb_pipe_candidate  # the classifier itself\n",
        "\n",
        "# 2) Preprocess your testâ€set once\n",
        "X_test_pre = prep.transform(X_test)\n",
        "\n",
        "# 3) Reconstruct feature names in the same order:\n",
        "#    â€“ continuous first\n",
        "#    â€“ then the OneHotEncoder names inside your `preprocessor`â€™s \"cat\" transformer\n",
        "num_feats = cont\n",
        "cat_ohe = prep.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
        "cat_ohe_names = cat_ohe.get_feature_names_out(cat)\n",
        "feat_names    = num_feats + list(cat_ohe_names)\n",
        "\n",
        "# 4) Compute permutation_importance on the _raw_ CatBoost model:\n",
        "r = permutation_importance(\n",
        "    cb_model,\n",
        "    X_test_pre, y_test,\n",
        "    scoring=\"roc_auc\",\n",
        "    n_repeats=20,\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 5) Build a DataFrame and plot the top 20\n",
        "imp_df = pd.DataFrame({\n",
        "    \"feature\":          feat_names,\n",
        "    \"mean_decrease_auc\": r.importances_mean\n",
        "}).sort_values(\"mean_decrease_auc\", ascending=False).head(20)\n",
        "\n",
        "plt.figure(figsize=(6, 8))\n",
        "plt.barh(imp_df[\"feature\"][::-1], imp_df[\"mean_decrease_auc\"][::-1])\n",
        "plt.xlabel(\"Mean decrease in AUC\")\n",
        "plt.title(\"Permutation importance â€“ CatBoost\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvyUWuG0-WO5"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•¡ Cell 11.3 â€“ Decision curve (CatBoost) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•—\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 1) Figure out where the preprocessor lives and where the CatBoost lives\n",
        "cb_obj = models[\"CatBoost\"]\n",
        "if isinstance(cb_obj, Pipeline):\n",
        "    prep     = cb_obj.named_steps[\"prep\"]\n",
        "    cb_model = cb_obj.named_steps[\"clf\"]\n",
        "else:\n",
        "    prep     = preprocessor    # your ColumnTransformer from Cell 4\n",
        "    cb_model = cb_obj          # raw CatBoostClassifier\n",
        "\n",
        "# 2) Turn X_test into the exact numeric matrix your model expects\n",
        "X_test_num = prep.transform(X_test)\n",
        "\n",
        "# 3) Get predicted probabilities for the positive class\n",
        "probs = cb_model.predict_proba(X_test_num)[:, 1]\n",
        "\n",
        "# 4) Build a simple â€œnet benefitâ€ curve\n",
        "thresholds = np.linspace(0, 1, 100)\n",
        "n          = len(y_test)\n",
        "event_rate = y_test.mean()\n",
        "\n",
        "nb = []\n",
        "for t in thresholds:\n",
        "    tp = ((probs >= t) & (y_test == 1)).sum()\n",
        "    fp = ((probs >= t) & (y_test == 0)).sum()\n",
        "    nb.append(tp/n - fp/n * (t/(1-t)))\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(thresholds, nb,       label=\"CatBoost\")\n",
        "plt.plot(thresholds, np.zeros_like(thresholds), \"--\", label=\"Treat none\")\n",
        "plt.plot(\n",
        "    thresholds,\n",
        "    event_rate - (1-event_rate)*(thresholds/(1-thresholds)),\n",
        "    \":\", label=\"Treat all\"\n",
        ")\n",
        "plt.xlabel(\"Decision threshold\")\n",
        "plt.ylabel(\"Net benefit\")\n",
        "plt.title(\"Decision Curve Analysis â€“ CatBoost\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•¡ Cell 11.4 â€“ Final evaluation on future hold-out for CatBoost (fixed) â”€â•â•â•â•â•—\n",
        "from sklearn.metrics         import (\n",
        "    roc_auc_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    RocCurveDisplay,\n",
        "    roc_curve\n",
        ")\n",
        "from sklearn.calibration     import calibration_curve\n",
        "from sklearn.metrics         import brier_score_loss\n",
        "import matplotlib.pyplot     as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1) Unpack your â€œmodels['CatBoost']â€, which might be either:\n",
        "#    a) a Pipeline(prepâ†’clf) or b) a raw CatBoostClassifier\n",
        "cb_obj = models[\"CatBoost\"]\n",
        "\n",
        "if hasattr(cb_obj, \"named_steps\"):\n",
        "    # (a) you stored a Pipeline\n",
        "    pre = cb_obj.named_steps[\"prep\"]    # your ColumnTransformer\n",
        "    clf = cb_obj.named_steps[\"clf\"]     # CatBoostClassifier\n",
        "    # apply the same preprocessing\n",
        "    X_val_num = pre.transform(X_test)\n",
        "else:\n",
        "    # (b) you stored a bare CatBoostClassifier\n",
        "    clf = cb_obj\n",
        "    # apply your preprocessor manually\n",
        "    X_val_num = preprocessor.transform(X_test)\n",
        "\n",
        "y_val = y_test\n",
        "\n",
        "# 2) Predict\n",
        "y_val_proba = clf.predict_proba(X_val_num)[:, 1]\n",
        "y_val_pred  = (y_val_proba >= 0.5).astype(int)\n",
        "\n",
        "# 3) Discrimination & classification metrics\n",
        "print(\"CatBoost AUC:           \", roc_auc_score(y_val, y_val_proba))\n",
        "print(\"CatBoost Confusion @0.5:\\n\", confusion_matrix(y_val, y_val_pred))\n",
        "print(\"\\nCatBoost Classification report:\\n\",\n",
        "      classification_report(y_val, y_val_pred))\n",
        "\n",
        "# 4) ROC curve\n",
        "RocCurveDisplay.from_predictions(y_val, y_val_proba)\n",
        "plt.title(\"CatBoost â€“ ROC on hold-out\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 5) Calibration curve + Brier score\n",
        "frac_pos, mean_pred = calibration_curve(y_val, y_val_proba, n_bins=10)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(mean_pred, frac_pos, \"o-\", label=\"CatBoost hold-out\")\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfect calibration\")\n",
        "plt.xlabel(\"Mean predicted probability\")\n",
        "plt.ylabel(\"Fraction of positives\")\n",
        "plt.title(\"CatBoost â€“ Calibration on hold-out\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"CatBoost Brier score:\", brier_score_loss(y_val, y_val_proba))\n",
        "\n",
        "# 6) Optimal threshold via Youdenâ€™s J\n",
        "fpr_cb, tpr_cb, thresh_cb = roc_curve(y_val, y_val_proba)\n",
        "j_scores_cb = tpr_cb - fpr_cb\n",
        "best_thresh_cb = thresh_cb[np.argmax(j_scores_cb)]\n",
        "print(f\"CatBoost optimal threshold (max J): {best_thresh_cb:.3f}\")\n"
      ],
      "metadata": {
        "id": "T4YbM77LasLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•¡ Cell 11.5 â€“ Calibrate your CatBoost on the build set â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.pipeline    import Pipeline\n",
        "\n",
        "# a) unpack your existing prepâ†’clf\n",
        "cb_pipe = models[\"CatBoost\"]\n",
        "if hasattr(cb_pipe, \"named_steps\"):\n",
        "    prep = cb_pipe.named_steps[\"prep\"]\n",
        "    base = cb_pipe.named_steps[\"clf\"]\n",
        "else:\n",
        "    prep = preprocessor\n",
        "    base = cb_pipe\n",
        "\n",
        "# b) build a small Pipeline with isotonic (or sigmoid) calibration\n",
        "calibrated_cb = Pipeline([\n",
        "    (\"prep\", prep),\n",
        "    (\"cal\",  CalibratedClassifierCV(\n",
        "                 estimator=base,     # <â€” use 'estimator', not 'base_estimator'\n",
        "                 method=\"isotonic\",  # or 'sigmoid'\n",
        "                 cv=3\n",
        "             ))\n",
        "])\n",
        "\n",
        "# c) fit only on your 80% build data\n",
        "calibrated_cb.fit(X_train, y_train)\n",
        "\n",
        "# d) swap into your models dict\n",
        "models[\"CatBoost_Calibrated\"] = calibrated_cb\n",
        "\n",
        "print(\"âœ… CatBoost_Calibrated added to models dict\")\n"
      ],
      "metadata": {
        "id": "AC_u_B5PKbH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•¡ Cell 11.6 â€“ Bootstrapâ€ensemble for CatBoost (fixed) â”€â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "from sklearn.utils     import resample\n",
        "from sklearn.metrics   import roc_auc_score\n",
        "from catboost          import CatBoostClassifier\n",
        "import numpy as np\n",
        "\n",
        "# unpack your pipeline\n",
        "cb_entry = models[\"CatBoost\"]\n",
        "if hasattr(cb_entry, \"named_steps\"):\n",
        "    prep     = cb_entry.named_steps[\"prep\"]\n",
        "    base_cb  = cb_entry.named_steps[\"clf\"]\n",
        "else:\n",
        "    prep     = preprocessor\n",
        "    base_cb  = cb_entry\n",
        "\n",
        "n_boot = 20\n",
        "boot_preds = np.zeros((len(X_test), n_boot))\n",
        "\n",
        "for i in range(n_boot):\n",
        "    # 1) bootstrapâ€resample the raw DataFrame + labels\n",
        "    Xb_df, yb = resample(X_train, y_train, random_state=RANDOM_STATE + i)\n",
        "    # 2) prepare_for_catboost (fills NaNs, casts cats to str)\n",
        "    Xb_cb = prepare_for_catboost(Xb_df, cat)\n",
        "    Xtest_cb = prepare_for_catboost(X_test, cat)\n",
        "    # 3) clone the CatBoost with identical hyperparams\n",
        "    cb = CatBoostClassifier(**base_cb.get_params())\n",
        "    # 4) fit on the DataFrame (CatBoost will handle numeric & string cats)\n",
        "    cb.fit(\n",
        "      Xb_cb, yb,\n",
        "      cat_features=cat_features_idx,\n",
        "      verbose=False\n",
        "    )\n",
        "    # 5) predict on your holdâ€out DataFrame\n",
        "    boot_preds[:, i] = cb.predict_proba(Xtest_cb)[:, 1]\n",
        "\n",
        "# aggregate\n",
        "y_mean = boot_preds.mean(axis=1)\n",
        "print(\"Bootstrapped CatBoost AUC:\", roc_auc_score(y_test, y_mean))\n"
      ],
      "metadata": {
        "id": "LIeKpgfwKiVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•¡ Cell 11.7 â€“ Compare Calibrated vs Bootstrap CatBoost on future holdâ€out â”€â•â•â•—\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics       import (\n",
        "    roc_auc_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    RocCurveDisplay,\n",
        "    roc_curve,\n",
        "    brier_score_loss\n",
        ")\n",
        "from sklearn.calibration   import calibration_curve\n",
        "from sklearn.utils         import resample\n",
        "from catboost              import CatBoostClassifier\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1) Calibrated CatBoost evaluation\n",
        "# ------------------------------------------------------------------------------\n",
        "cal_cb = models[\"CatBoost_Calibrated\"]\n",
        "X_val, y_val = X_test, y_test\n",
        "\n",
        "# predict\n",
        "y_cal_proba = cal_cb.predict_proba(X_val)[:, 1]\n",
        "y_cal_pred  = cal_cb.predict(X_val)\n",
        "\n",
        "# metrics\n",
        "print(\"=== Calibrated CatBoost on holdâ€out ===\")\n",
        "print(\"AUC:           \", roc_auc_score(y_val, y_cal_proba))\n",
        "print(\"Confusion @0.5:\\n\", confusion_matrix(y_val, y_cal_pred))\n",
        "print(classification_report(y_val, y_cal_pred))\n",
        "\n",
        "# ROC\n",
        "RocCurveDisplay.from_predictions(y_val, y_cal_proba)\n",
        "plt.title(\"Calibrated CatBoost â€“ ROC\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calibration curve + Brier\n",
        "frac_pos_c, mean_pred_c = calibration_curve(y_val, y_cal_proba, n_bins=10)\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(mean_pred_c, frac_pos_c, \"o-\", label=\"Calibrated\")\n",
        "plt.plot([0,1],[0,1],\"k--\", label=\"Ideal\")\n",
        "plt.xlabel(\"Mean predicted probability\")\n",
        "plt.ylabel(\"Fraction of positives\")\n",
        "plt.title(\"Calibrated CatBoost â€“ Calibration\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Brier score:\", brier_score_loss(y_val, y_cal_proba))\n",
        "print()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2) Bootstrapâ€ensemble CatBoost evaluation\n",
        "# ------------------------------------------------------------------------------\n",
        "# unpack raw CatBoost\n",
        "cb_entry = models[\"CatBoost\"]\n",
        "if hasattr(cb_entry, \"named_steps\"):\n",
        "    prep    = cb_entry.named_steps[\"prep\"]\n",
        "    base_cb = cb_entry.named_steps[\"clf\"]\n",
        "else:\n",
        "    prep    = preprocessor\n",
        "    base_cb = cb_entry\n",
        "\n",
        "n_boot = 20\n",
        "boot_preds = np.zeros((len(X_val), n_boot))\n",
        "for i in range(n_boot):\n",
        "    Xb_df, yb = resample(X_train, y_train, random_state=RANDOM_STATE+i)\n",
        "    Xb_cb = prepare_for_catboost(Xb_df, cat)\n",
        "    Xval_cb = prepare_for_catboost(X_val, cat)\n",
        "    cb = CatBoostClassifier(**base_cb.get_params())\n",
        "    cb.fit(Xb_cb, yb, cat_features=cat_features_idx, verbose=False)\n",
        "    boot_preds[:, i] = cb.predict_proba(Xval_cb)[:, 1]\n",
        "\n",
        "y_boot_mean = boot_preds.mean(axis=1)\n",
        "\n",
        "print(\"=== Bootstrapâ€ensemble CatBoost on holdâ€out ===\")\n",
        "print(\"AUC:           \", roc_auc_score(y_val, y_boot_mean))\n",
        "# hardâ€classify at 0.5\n",
        "y_boot_pred = (y_boot_mean >= 0.5).astype(int)\n",
        "print(\"Confusion @0.5:\\n\", confusion_matrix(y_val, y_boot_pred))\n",
        "print(classification_report(y_val, y_boot_pred))\n",
        "\n",
        "# ROC\n",
        "RocCurveDisplay.from_predictions(y_val, y_boot_mean)\n",
        "plt.title(\"Bootstrap CatBoost â€“ ROC\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calibration curve + Brier\n",
        "frac_pos_b, mean_pred_b = calibration_curve(y_val, y_boot_mean, n_bins=10)\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(mean_pred_b, frac_pos_b, \"o-\", label=\"Bootstrapped\")\n",
        "plt.plot([0,1],[0,1],\"k--\", label=\"Ideal\")\n",
        "plt.xlabel(\"Mean predicted probability\")\n",
        "plt.ylabel(\"Fraction of positives\")\n",
        "plt.title(\"Bootstrap CatBoost â€“ Calibration\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Brier score:\", brier_score_loss(y_val, y_boot_mean))\n"
      ],
      "metadata": {
        "id": "AF2HxnIaLkvl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyN5dmSzb6oLp7EmEecM5rN3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}